{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IoULoss(nn.Module) :\n",
    "    def __init__(self, method = 'IoU') :\n",
    "        super().__init__()\n",
    "        self.method = method\n",
    "\n",
    "    def forward(self, inp, target) :\n",
    "        '''\n",
    "        input : (B, # of bboxes, 6)\n",
    "        '''\n",
    "        inp_w = inp[..., 2:3]\n",
    "        inp_h = inp[..., 3:4]\n",
    "        target_w = target[..., 2:3]\n",
    "        target_h = target[..., 3:4]\n",
    "\n",
    "        inp_area = inp_w * inp_h\n",
    "        target_area = target_w * target_h\n",
    "\n",
    "        inp_xmin = inp[..., 0:1] - inp_w / 2\n",
    "        inp_ymin = inp[..., 1:2] - inp_h / 2\n",
    "        inp_xmax = inp[..., 0:1] + inp_w / 2\n",
    "        inp_ymax = inp[..., 1:2] + inp_w / 2\n",
    "\n",
    "        target_xmin = target[..., 0:1] - target_w / 2\n",
    "        target_ymin = target[..., 1:2] - target_h / 2\n",
    "        target_xmax = target[..., 0:1] + target_w / 2\n",
    "        target_ymax = target[..., 1:2] + target_w / 2\n",
    "        \n",
    "        inp_topleft = torch.cat([inp_xmin, inp_ymin], axis = -1)\n",
    "        target_topleft = torch.cat([target_xmin, target_ymin], axis = -1)\n",
    "\n",
    "        inp_bottomright = torch.cat([inp_xmax, inp_ymax], axis = -1)\n",
    "        target_bottomright = torch.cat([target_xmax, target_ymax], axis = -1)\n",
    "\n",
    "        intersection_top_left = torch.max(inp_topleft, target_topleft)\n",
    "        intersection_bottom_right = torch.min(inp_bottomright, target_bottomright)\n",
    "\n",
    "\n",
    "\n",
    "        area_inter = torch.prod(\n",
    "            torch.clip(intersection_bottom_right - intersection_top_left, min = 0 , max = None), -1).unsqueeze(-1)\n",
    "\n",
    "        iou = area_inter / (inp_area + target_area - area_inter + 1e-9)\n",
    "\n",
    "        # GIoU : IoU - |C \\ (A U B)| over C. C는 bbox와 GT를 모두 포함하는 최소 크기의 박스.\n",
    "        C_top_left = torch.min(inp_topleft, target_topleft)\n",
    "        C_bottom_right = torch.max(inp_bottomright, target_bottomright)\n",
    "        C_area = torch.prod(C_bottom_right - C_top_left, -1).unsqueeze(-1)\n",
    "\n",
    "        # DIoU : 중심좌표 반영. 1 - IoU + euclidean(pred_center, gt_center) / (diagonal length of C)**2 . C는 bbox와 GT를 모두 포함하는 최소 크기의 박스.\n",
    "        euclidean = torch.sqrt(torch.sum((inp[..., 0:2] - target[..., 0:2]) ** 2, dim = -1)).unsqueeze(-1)\n",
    "        diagonal_length_C = torch.sum((C_bottom_right - C_top_left) ** 2, dim = -1).unsqueeze(-1)\n",
    "\n",
    "        # CIoU : overlap area, central point distance, aspect ratio 고려. \n",
    "        # 1 - IoU + 1 - IoU + euclidean(pred_center, gt_center) / (diagonal length of C)**2 + aspect_ratio_resemblance * alpha\n",
    "        # aspect_ratio_resemblance = 4 / pi**2 (arctan(w_gt/h_gt) - arctan(w_pred/h_pred)) ** 2. \n",
    "        # (4/pi**2) * (arctan(w/h)) range from -0.5 to 0.5\n",
    "        # alpha = positive trade-off parameter. aspect_ratio_resemblance / (1-IoU) + aspect_ratio_resemblance. IoU가 클수록 aspect_ratio_resemblance의 영향력을 키운다.\n",
    "        aspect_ratio_resemblance = (4 / torch.pi ** 2) * (torch.atan(target_w / target_h) - torch.atan(inp_w / inp_h)) ** 2\n",
    "        alpha = aspect_ratio_resemblance / ( (1 - iou) + aspect_ratio_resemblance)\n",
    "\n",
    "        if self.method == 'IoU' : \n",
    "            return 1 - iou\n",
    "        elif self.method == 'GIoU' :\n",
    "            return 1 - (iou - (C_area - (inp_area + target_area - area_inter)) / C_area)\n",
    "        elif self.method == 'DIoU' :\n",
    "            return 1 - iou + (euclidean / diagonal_length_C)\n",
    "        elif self.method == 'CIoU' :\n",
    "            return 1 - iou + (euclidean / diagonal_length_C) + alpha * aspect_ratio_resemblance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test case 1. IoU 0.36\n",
    "# test case 2. IoU 1.\n",
    "# test case 3. IoU 0\n",
    "# test case 4. IoU 0\n",
    "pred = torch.tensor([[0.5, 0.5, 0.5, 0.5],\n",
    "                     [0.5, 0.5, 0.3, 0.3],\n",
    "                     [0.1, 0.3, 0.2, 0.2],\n",
    "                     [0.1, 0.3, 0.2, 0.2]\n",
    "                ]).unsqueeze(0) # for batch\n",
    "\n",
    "gt = torch.tensor([[0.7, 0.7, 0.4, 0.4],\n",
    "                   [0.5, 0.5, 0.3, 0.3],\n",
    "                   [0.6, 0.3, 0.2, 0.2],\n",
    "                   [0.3, 0.3, 0.2, 0.2]\n",
    "                ]).unsqueeze(0) # for batch\n",
    "\n",
    "pred = torch.randn(16, 3, 13, 13, 4)\n",
    "gt = torch.randn(16, 3, 13, 13, 4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "iouloss = IoULoss(method = 'CIoU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 3, 13, 13, 1])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iouloss(pred, gt).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.17985611510791366"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.0625 / (0.25 + 0.16 - 0.0625)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.141592653589793"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.4823])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.atan(torch.tensor([1/6 * torch.pi]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7071067811865476"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2 **(1/2) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 64, 248, 248])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# k = {1, 5, 9, 13}\n",
    "# dilated convolution\n",
    "# kernel size 3: dilated ratio equals to k, max-pooling of stride 1, \n",
    "k = 5\n",
    "dilated_conv = torch.nn.Conv2d(3, 64, kernel_size = 3, stride = 1, padding = 1, dilation= k)\n",
    "\n",
    "batch_size = 4\n",
    "\n",
    "inp = torch.randn(batch_size, 3, 256, 256)\n",
    "\n",
    "dilated_conv(inp).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 32, 64, 64])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bn = nn.BatchNorm2d(32)\n",
    "samp = torch.randn((1, 32, 64, 64))\n",
    "\n",
    "bn(samp).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1e-05"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bn.eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChannelPool(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return torch.cat( (torch.max(x,1)[0].unsqueeze(1), torch.mean(x,1).unsqueeze(1)), dim=1 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 64, 64])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cp = ChannelPool()\n",
    "\n",
    "cp(samp).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CSPDenseBlock(nn.Module) :\n",
    "    '''\n",
    "    implement Cross Stage Partial Connection\n",
    "    '''\n",
    "    def __int__(self, activation = 'mish') :\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channel, mid_channel, 1, stride = 1)\n",
    "        self.conv2 = nn.Conv2d(mid_channel, out_channel, 3, stride = 1, padding = 1)\n",
    "        if activation == 'mish' :\n",
    "            self.activation = nn.mish()\n",
    "\n",
    "    def forward(self, x) :\n",
    "        # split channel-wise\n",
    "        split = x.size[1] // 2\n",
    "        part1 = x[:, split:, ...]\n",
    "        part2 = x[:, :split, ...]\n",
    "\n",
    "        return torch.cat([part1, self.activation(self.conv2(self.conv1(part2)))], dim = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 15, 224, 224])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DenseNet BottleNeck\n",
    "class BottleNeck(nn.Module):\n",
    "    def __init__(self, in_channels, growth_rate):\n",
    "        super().__init__()\n",
    "        inner_channels = 4 * growth_rate\n",
    "\n",
    "        self.residual = nn.Sequential(\n",
    "            nn.BatchNorm2d(in_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels, inner_channels, 1, stride=1, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(inner_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(inner_channels, growth_rate, 3, stride=1, padding=1, bias=False)\n",
    "        )\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.cat([self.shortcut(x), self.residual(x)], 1)\n",
    "\n",
    "\n",
    "bottleneck = BottleNeck(in_channels = 3 , growth_rate= 12)\n",
    "\n",
    "bottleneck(torch.randn(1, 3, 224, 224)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 15, 112, 112])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transition Block: reduce feature map size and number of channels\n",
    "class Transition(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "\n",
    "        self.down_sample = nn.Sequential(\n",
    "            nn.BatchNorm2d(in_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels, out_channels, 1, stride=1, padding=0, bias=False),\n",
    "            nn.AvgPool2d(2, stride=2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.down_sample(x)\n",
    "\n",
    "transition = Transition(3, 15)\n",
    "\n",
    "transition(torch.randn(1, 3, 224, 224)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DenseNet BottleNeck\n",
    "class BottleNeck(nn.Module):\n",
    "    def __init__(self, in_channels, growth_rate):\n",
    "        super().__init__()\n",
    "        inner_channels = 4 * growth_rate\n",
    "\n",
    "        self.residual = nn.Sequential(\n",
    "            nn.BatchNorm2d(in_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels, inner_channels, 1, stride=1, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(inner_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(inner_channels, growth_rate, 3, stride=1, padding=1, bias=False)\n",
    "        )\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.cat([self.shortcut(x), self.residual(x)], 1)\n",
    "\n",
    "# Transition Block: reduce feature map size and number of channels\n",
    "class Transition(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "\n",
    "        self.down_sample = nn.Sequential(\n",
    "            nn.BatchNorm2d(in_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels, out_channels, 1, stride=1, padding=0, bias=False),\n",
    "            nn.AvgPool2d(2, stride=2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.down_sample(x)\n",
    "\n",
    "# DenseNet\n",
    "class DenseNet(nn.Module):\n",
    "    def __init__(self, nblocks, growth_rate=12, reduction=0.5, num_classes=10, init_weights=True):\n",
    "        super().__init__()\n",
    "\n",
    "        self.growth_rate = growth_rate\n",
    "        inner_channels = 2 * growth_rate # output channels of conv1 before entering Dense Block\n",
    "\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(3, inner_channels, 7, stride=2, padding=3),\n",
    "            nn.MaxPool2d(3, 2, padding=1)\n",
    "        )\n",
    "\n",
    "        self.features = nn.Sequential()\n",
    "\n",
    "        for i in range(len(nblocks)-1):\n",
    "            self.features.add_module('dense_block_{}'.format(i), self._make_dense_block(nblocks[i], inner_channels))\n",
    "            inner_channels += growth_rate * nblocks[i]\n",
    "            out_channels = int(reduction * inner_channels)\n",
    "            self.features.add_module('transition_layer_{}'.format(i), Transition(inner_channels, out_channels))\n",
    "            inner_channels = out_channels \n",
    "        \n",
    "        self.features.add_module('dense_block_{}'.format(len(nblocks)-1), self._make_dense_block(nblocks[len(nblocks)-1], inner_channels))\n",
    "        inner_channels += growth_rate * nblocks[len(nblocks)-1]\n",
    "        self.features.add_module('bn', nn.BatchNorm2d(inner_channels))\n",
    "        self.features.add_module('relu', nn.ReLU())\n",
    "\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.linear = nn.Linear(inner_channels, num_classes)\n",
    "\n",
    "        # weight initialization\n",
    "        if init_weights:\n",
    "            self._initialize_weights()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        print(x.shape)\n",
    "        x = self.features(x)\n",
    "        print(x.shape)\n",
    "        x = self.avg_pool(x)\n",
    "        print(x.shape)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.linear(x)\n",
    "        return x\n",
    "\n",
    "    def _make_dense_block(self, nblock, inner_channels):\n",
    "        dense_block = nn.Sequential()\n",
    "        for i in range(nblock):\n",
    "            dense_block.add_module('bottle_neck_layer_{}'.format(i), BottleNeck(inner_channels, self.growth_rate))\n",
    "            inner_channels += self.growth_rate\n",
    "        return dense_block\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, 0, 0.01)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "def DenseNet_121():\n",
    "    return DenseNet([6, 12, 24, 6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DenseNet_121()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 24, 56, 56])\n",
      "torch.Size([1, 264, 7, 7])\n",
      "torch.Size([1, 264, 1, 1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0327, -0.0391,  0.0829, -0.0473, -0.0329, -0.1048,  0.0238, -0.0491,\n",
       "          0.0917,  0.0419]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(torch.randn(1,3, 224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
