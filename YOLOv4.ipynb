{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IoULoss(nn.Module) :\n",
    "    def __init__(self, method = 'IoU') :\n",
    "        super().__init__()\n",
    "        self.method = method\n",
    "\n",
    "    def forward(self, inp, target) :\n",
    "        '''\n",
    "        input : (B, # of bboxes, 6)\n",
    "        '''\n",
    "        inp_w = inp[..., 2:3]\n",
    "        inp_h = inp[..., 3:4]\n",
    "        target_w = target[..., 2:3]\n",
    "        target_h = target[..., 3:4]\n",
    "\n",
    "        inp_area = inp_w * inp_h\n",
    "        target_area = target_w * target_h\n",
    "\n",
    "        inp_xmin = inp[..., 0:1] - inp_w / 2\n",
    "        inp_ymin = inp[..., 1:2] - inp_h / 2\n",
    "        inp_xmax = inp[..., 0:1] + inp_w / 2\n",
    "        inp_ymax = inp[..., 1:2] + inp_w / 2\n",
    "\n",
    "        target_xmin = target[..., 0:1] - target_w / 2\n",
    "        target_ymin = target[..., 1:2] - target_h / 2\n",
    "        target_xmax = target[..., 0:1] + target_w / 2\n",
    "        target_ymax = target[..., 1:2] + target_w / 2\n",
    "        \n",
    "        inp_topleft = torch.cat([inp_xmin, inp_ymin], axis = -1)\n",
    "        target_topleft = torch.cat([target_xmin, target_ymin], axis = -1)\n",
    "\n",
    "        inp_bottomright = torch.cat([inp_xmax, inp_ymax], axis = -1)\n",
    "        target_bottomright = torch.cat([target_xmax, target_ymax], axis = -1)\n",
    "\n",
    "        intersection_top_left = torch.max(inp_topleft, target_topleft)\n",
    "        intersection_bottom_right = torch.min(inp_bottomright, target_bottomright)\n",
    "\n",
    "\n",
    "\n",
    "        area_inter = torch.prod(\n",
    "            torch.clip(intersection_bottom_right - intersection_top_left, min = 0 , max = None), -1).unsqueeze(-1)\n",
    "\n",
    "        iou = area_inter / (inp_area + target_area - area_inter + 1e-9)\n",
    "\n",
    "        # GIoU : IoU - |C \\ (A U B)| over C. C는 bbox와 GT를 모두 포함하는 최소 크기의 박스.\n",
    "        C_top_left = torch.min(inp_topleft, target_topleft)\n",
    "        C_bottom_right = torch.max(inp_bottomright, target_bottomright)\n",
    "        C_area = torch.prod(C_bottom_right - C_top_left, -1).unsqueeze(-1)\n",
    "\n",
    "        # DIoU : 중심좌표 반영. 1 - IoU + euclidean(pred_center, gt_center) / (diagonal length of C)**2 . C는 bbox와 GT를 모두 포함하는 최소 크기의 박스.\n",
    "        euclidean = torch.sqrt(torch.sum((inp[..., 0:2] - target[..., 0:2]) ** 2, dim = -1)).unsqueeze(-1)\n",
    "        diagonal_length_C = torch.sum((C_bottom_right - C_top_left) ** 2, dim = -1).unsqueeze(-1)\n",
    "\n",
    "        # CIoU : overlap area, central point distance, aspect ratio 고려. \n",
    "        # 1 - IoU + 1 - IoU + euclidean(pred_center, gt_center) / (diagonal length of C)**2 + aspect_ratio_resemblance * alpha\n",
    "        # aspect_ratio_resemblance = 4 / pi**2 (arctan(w_gt/h_gt) - arctan(w_pred/h_pred)) ** 2. \n",
    "        # (4/pi**2) * (arctan(w/h)) range from -0.5 to 0.5\n",
    "        # alpha = positive trade-off parameter. aspect_ratio_resemblance / (1-IoU) + aspect_ratio_resemblance. IoU가 클수록 aspect_ratio_resemblance의 영향력을 키운다.\n",
    "        aspect_ratio_resemblance = (4 / torch.pi ** 2) * (torch.atan(target_w / target_h) - torch.atan(inp_w / inp_h)) ** 2\n",
    "        alpha = aspect_ratio_resemblance / ( (1 - iou) + aspect_ratio_resemblance)\n",
    "\n",
    "        if self.method == 'IoU' : \n",
    "            return 1 - iou\n",
    "        elif self.method == 'GIoU' :\n",
    "            return 1 - (iou - (C_area - (inp_area + target_area - area_inter)) / C_area)\n",
    "        elif self.method == 'DIoU' :\n",
    "            return 1 - iou + (euclidean / diagonal_length_C)\n",
    "        elif self.method == 'CIoU' :\n",
    "            return 1 - iou + (euclidean / diagonal_length_C) + alpha * aspect_ratio_resemblance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test case 1. IoU 0.36\n",
    "# test case 2. IoU 1.\n",
    "# test case 3. IoU 0\n",
    "# test case 4. IoU 0\n",
    "pred = torch.tensor([[0.5, 0.5, 0.5, 0.5],\n",
    "                     [0.5, 0.5, 0.3, 0.3],\n",
    "                     [0.1, 0.3, 0.2, 0.2],\n",
    "                     [0.1, 0.3, 0.2, 0.2]\n",
    "                ]).unsqueeze(0) # for batch\n",
    "\n",
    "gt = torch.tensor([[0.7, 0.7, 0.4, 0.4],\n",
    "                   [0.5, 0.5, 0.3, 0.3],\n",
    "                   [0.6, 0.3, 0.2, 0.2],\n",
    "                   [0.3, 0.3, 0.2, 0.2]\n",
    "                ]).unsqueeze(0) # for batch\n",
    "\n",
    "pred = torch.randn(16, 3, 13, 13, 4)\n",
    "gt = torch.randn(16, 3, 13, 13, 4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "iouloss = IoULoss(method = 'CIoU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 3, 13, 13, 1])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iouloss(pred, gt).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.17985611510791366"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.0625 / (0.25 + 0.16 - 0.0625)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.141592653589793"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.4823])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.atan(torch.tensor([1/6 * torch.pi]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7071067811865476"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2 **(1/2) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 64, 248, 248])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# k = {1, 5, 9, 13}\n",
    "# dilated convolution\n",
    "# kernel size 3: dilated ratio equals to k, max-pooling of stride 1, \n",
    "k = 5\n",
    "dilated_conv = torch.nn.Conv2d(3, 64, kernel_size = 3, stride = 1, padding = 1, dilation= k)\n",
    "\n",
    "batch_size = 4\n",
    "\n",
    "inp = torch.randn(batch_size, 3, 256, 256)\n",
    "\n",
    "dilated_conv(inp).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 32, 64, 64])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bn = nn.BatchNorm2d(32)\n",
    "samp = torch.randn((1, 32, 64, 64))\n",
    "\n",
    "bn(samp).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1e-05"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bn.eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChannelPool(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return torch.cat( (torch.max(x,1)[0].unsqueeze(1), torch.mean(x,1).unsqueeze(1)), dim=1 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 64, 24, 24])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseblock = BaseBlock(3, 64, 3, 1, 1)\n",
    "baseblock(torch.randn(1,3,24,24)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseBlock(nn.Module) :\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride = 1, padding = 0, act_fn = 'mish') :\n",
    "        super().__init__()\n",
    "        if act_fn.lower() == 'mish' :\n",
    "            activation = nn.Mish()\n",
    "        elif act_fn.lower() == 'leakyrelu' :\n",
    "            activation = nn.LeakyReLU()\n",
    "        elif act_fn.lower() == 'relu' :\n",
    "            activation = nn.ReLU()\n",
    "        else :\n",
    "            raise ValueError(f'{act_fn} activation function is not covered. add on DarkNetBottleneck module.')\n",
    "\n",
    "        self.activation = activation\n",
    "        self.conv = nn.Sequential(\n",
    "                        nn.Conv2d(in_channels, out_channels, kernel_size = kernel_size, stride = stride, padding = padding),\n",
    "                        nn.BatchNorm2d(out_channels),\n",
    "                        self.activation)\n",
    "                        \n",
    "    def forward(self, x) :\n",
    "        return self.conv(x)\n",
    "        \n",
    "\n",
    "class DarkNetBottleneck(nn.Module) :\n",
    "    def __init__(self, in_channels, out_channels, expansion = 2, act_fn = 'mish') :\n",
    "        super().__init__()\n",
    "\n",
    "        mid_channels = int(out_channels / expansion)\n",
    "        self.conv1 = BaseBlock(in_channels, mid_channels, act_fn = act_fn, kernel_size = 1, stride = 1, padding = 0)\n",
    "        self.conv2 = BaseBlock(mid_channels, out_channels, act_fn = act_fn, kernel_size = 3, stride = 1, padding = 1)\n",
    "\n",
    "    def forward(self, x) :\n",
    "        residual = x\n",
    "        output = self.conv1(x)\n",
    "        output = self.conv2(output)\n",
    "        output += residual\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CSPStage(nn.Module) : \n",
    "    def __init__(self, in_channels, mid_channels, out_channels, block_fn, expansion, act_fn, num_blocks) :\n",
    "        '''\n",
    "        input x will be channel-wise splited into part1 and part2.\n",
    "        During CSP, only part2 will go through block_fn.\n",
    "        downsampling layer before CSP, and transition after concatenation.\n",
    "        input x : (B, C, H, W)\n",
    "        part1&part2 : (B, C // 2, H, W)\n",
    "        C should be divisible by 2.\n",
    "\n",
    "        in_channels : input channel of downsample layer. downsample layer reduce the feature size by 2\n",
    "        mid_channels : output channel of downsample layer and input channel of cspblock\n",
    "        block_fn : block function that will be applied on part2. For Darknet53, we are going to use DarkNetBottleneck.\n",
    "        expansion : expansion of block_fn. e.g) expansion=2, C_in -> C_out//2 -> C_out. C means channel.\n",
    "        act_fn : activation function. For DarkNet53, we are going to use mish.\n",
    "        num_blocks : number of iterations of block_fn\n",
    "        '''\n",
    "        super().__init__()\n",
    "        self.downsample = BaseBlock(in_channels, mid_channels, kernel_size = 3, stride = 2, padding = 1)\n",
    "        self.cspblock = nn.Sequential()\n",
    "\n",
    "        block_channels = mid_channels // 2 # input_channel for part2\n",
    "\n",
    "        for i in range(num_blocks) :\n",
    "\n",
    "            block = block_fn(in_channels = block_channels, \n",
    "                                             out_channels = block_channels,\n",
    "                                             expansion = expansion,\n",
    "                                             act_fn = act_fn\n",
    "                                             ) # this only covers DarkNetBottleneck module.\n",
    "\n",
    "            self.cspblock.add_module(f'partial_block_{i+1}', block )\n",
    "            \n",
    "        self.after_cspblock = BaseBlock(in_channels = block_channels, \n",
    "                                        out_channels = block_channels,\n",
    "                                        kernel_size = 1,\n",
    "                                        stride = 1,\n",
    "                                        padding = 0,\n",
    "                                        )\n",
    "        \n",
    "        self.transition = BaseBlock(in_channels = 2 * block_channels, \n",
    "                                        out_channels = out_channels,\n",
    "                                        kernel_size = 1,\n",
    "                                        stride = 1,\n",
    "                                        padding = 0,\n",
    "                                        )\n",
    "\n",
    "\n",
    "    def forward(self, x) :\n",
    "        x = self.downsample(x)\n",
    "        split = x.shape[1] // 2\n",
    "        part1, part2 = x[:, :split], x[:, split:]\n",
    "\n",
    "        part2 = self.cspblock(part2)\n",
    "        part2 = self.after_cspblock(part2).contiguous()\n",
    "\n",
    "        output = torch.cat([part1, part2], dim = 1)\n",
    "        output = self.transition(output)\n",
    "\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv2d(3, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modules = nn.ModuleList()\n",
    "\n",
    "modules.add_module('abc', nn.Conv2d(3,6,3,1,1,1))\n",
    "\n",
    "modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DarkNet53(nn.Module) :\n",
    "    '''\n",
    "    initial layer : conv(3,3,32)/1, mish\n",
    "\n",
    "    in_channels  : [3, 32,  64,  64, 128,  256]\n",
    "    mid_channels : [64, 128, 256, 512, 1024]\n",
    "    out_channels : [64,  64, 128, 256,  512]\n",
    "\n",
    "    num_blocks of cspstage : [1,2,8,8,4]\n",
    "    '''\n",
    "    def __init__(self, act_fn, block_fn, expansion, in_channels_list = [], mid_channels_list = [], out_channels_list = [], num_blocks_list = []) :\n",
    "        super().__init__()\n",
    "        \n",
    "        self.input_layer = BaseBlock(in_channels_list[0], in_channels_list[1], kernel_size = 3, stride = 1, padding = 0)\n",
    "        \n",
    "        self.modules = nn.Modulelist()\n",
    "        for i, num_blocks in enumerate(num_blocks_list) :\n",
    "            \n",
    "            cspstage = CSPStage(in_channels = in_channels_list[i], \n",
    "                            mid_channels = mid_channels_list[i], \n",
    "                            out_channels = out_channels_list[i], \n",
    "                            block_fn = block_fn, \n",
    "                            expansion = expansion, \n",
    "                            act_fn = act_fn, num_blocks = num_blocks)\n",
    "            self.modules.add_module(f'CSPStage_{i+1}', cspstage)\n",
    "\n",
    "    def forward(self, x) :\n",
    "        output = self.input_layer(x)\n",
    "        for stage in self.modules :\n",
    "            output = stage(output)\n",
    "        return output\n",
    "\n",
    "\n",
    "            \n",
    "\n",
    "                                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_channels_list  = [3, 32,  64,  64, 128,  256]\n",
    "mid_channels_list = [64, 128, 256, 512, 1024]\n",
    "out_channels_list = [64,  64, 128, 256,  512]\n",
    "\n",
    "\n",
    "model = DarkNet53(act_fn = 'mish', block_fn = DarkNetBottleneck, expansion = 2, \n",
    "                    in_channels_list = in_channels_list,\n",
    "                    mid_channels_list = mid_channels_list,\n",
    "                    out_channels_list = out_channels_list\n",
    "                    )\n",
    "\n",
    "model(torch.randn((1,3,)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# DenseNet BottleNeck\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mBottleNeck\u001b[39;00m(nn\u001b[39m.\u001b[39mModule):\n\u001b[0;32m      3\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, in_channels, growth_rate):\n\u001b[0;32m      4\u001b[0m         \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "# DenseNet BottleNeck\n",
    "class BottleNeck(nn.Module):\n",
    "    def __init__(self, in_channels, growth_rate):\n",
    "        super().__init__()\n",
    "        inner_channels = 4 * growth_rate\n",
    "\n",
    "        self.residual = nn.Sequential(\n",
    "            nn.BatchNorm2d(in_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels, inner_channels, 1, stride=1, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(inner_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(inner_channels, growth_rate, 3, stride=1, padding=1, bias=False)\n",
    "        )\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.cat([self.shortcut(x), self.residual(x)], 1)\n",
    "\n",
    "\n",
    "bottleneck = BottleNeck(in_channels = 3 , growth_rate= 12)\n",
    "\n",
    "bottleneck(torch.randn(1, 3, 224, 224)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 15, 112, 112])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transition Block: reduce feature map size and number of channels\n",
    "class Transition(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "\n",
    "        self.down_sample = nn.Sequential(\n",
    "            nn.BatchNorm2d(in_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels, out_channels, 1, stride=1, padding=0, bias=False),\n",
    "            nn.AvgPool2d(2, stride=2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.down_sample(x)\n",
    "\n",
    "transition = Transition(3, 15)\n",
    "\n",
    "transition(torch.randn(1, 3, 224, 224)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DenseNet BottleNeck\n",
    "class BottleNeck(nn.Module):\n",
    "    def __init__(self, in_channels, growth_rate):\n",
    "        super().__init__()\n",
    "        inner_channels = 4 * growth_rate\n",
    "\n",
    "        self.residual = nn.Sequential(\n",
    "            nn.BatchNorm2d(in_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels, inner_channels, 1, stride=1, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(inner_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(inner_channels, growth_rate, 3, stride=1, padding=1, bias=False)\n",
    "        )\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.cat([self.shortcut(x), self.residual(x)], 1)\n",
    "\n",
    "# Transition Block: reduce feature map size and number of channels\n",
    "class Transition(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "\n",
    "        self.down_sample = nn.Sequential(\n",
    "            nn.BatchNorm2d(in_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels, out_channels, 1, stride=1, padding=0, bias=False),\n",
    "            nn.AvgPool2d(2, stride=2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.down_sample(x)\n",
    "\n",
    "# DenseNet\n",
    "class DenseNet(nn.Module):\n",
    "    def __init__(self, nblocks, growth_rate=12, reduction=0.5, num_classes=10, init_weights=True):\n",
    "        super().__init__()\n",
    "\n",
    "        self.growth_rate = growth_rate\n",
    "        inner_channels = 2 * growth_rate # output channels of conv1 before entering Dense Block\n",
    "\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(3, inner_channels, 7, stride=2, padding=3),\n",
    "            nn.MaxPool2d(3, 2, padding=1)\n",
    "        )\n",
    "\n",
    "        self.features = nn.Sequential()\n",
    "\n",
    "        for i in range(len(nblocks)-1):\n",
    "            self.features.add_module('dense_block_{}'.format(i), self._make_dense_block(nblocks[i], inner_channels))\n",
    "            inner_channels += growth_rate * nblocks[i]\n",
    "            out_channels = int(reduction * inner_channels)\n",
    "            self.features.add_module('transition_layer_{}'.format(i), Transition(inner_channels, out_channels))\n",
    "            inner_channels = out_channels \n",
    "        \n",
    "        self.features.add_module('dense_block_{}'.format(len(nblocks)-1), self._make_dense_block(nblocks[len(nblocks)-1], inner_channels))\n",
    "        inner_channels += growth_rate * nblocks[len(nblocks)-1]\n",
    "        self.features.add_module('bn', nn.BatchNorm2d(inner_channels))\n",
    "        self.features.add_module('relu', nn.ReLU())\n",
    "\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.linear = nn.Linear(inner_channels, num_classes)\n",
    "\n",
    "        # weight initialization\n",
    "        if init_weights:\n",
    "            self._initialize_weights()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        print(x.shape)\n",
    "        x = self.features(x)\n",
    "        print(x.shape)\n",
    "        x = self.avg_pool(x)\n",
    "        print(x.shape)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.linear(x)\n",
    "        return x\n",
    "\n",
    "    def _make_dense_block(self, nblock, inner_channels):\n",
    "        dense_block = nn.Sequential()\n",
    "        for i in range(nblock):\n",
    "            dense_block.add_module('bottle_neck_layer_{}'.format(i), BottleNeck(inner_channels, self.growth_rate))\n",
    "            inner_channels += self.growth_rate\n",
    "        return dense_block\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, 0, 0.01)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "def DenseNet_121():\n",
    "    return DenseNet([6, 12, 24, 6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DenseNet_121()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 24, 56, 56])\n",
      "torch.Size([1, 264, 7, 7])\n",
      "torch.Size([1, 264, 1, 1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0327, -0.0391,  0.0829, -0.0473, -0.0329, -0.1048,  0.0238, -0.0491,\n",
       "          0.0917,  0.0419]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(torch.randn(1,3, 224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
