{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6900)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sigmoid(torch.tensor(0.8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([], size=(3, 0))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([  [], [[1,2],[3,4]] , [[1,2]]         ] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "numgrid = 7\n",
    "numbox = 5\n",
    "num_classes = 13\n",
    "\n",
    "labelgrid = torch.randn((batch_size, numgrid, numgrid, numbox, 5 + num_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 7, 7, 5])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros_like(labelgrid[..., 0]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5000, 0.5000, 0.5000, 0.5000]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sigmoid(torch.tensor([[0,0,0,0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2x3x3x4=\n",
    "seq = torch.arange(2*3*3*5*4).contiguous()\n",
    "\n",
    "grid = seq.reshape(2,3,3,5,4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[[0, 0, 0, 0],\n",
       "           [0, 0, 0, 0],\n",
       "           [0, 0, 0, 0]],\n",
       "\n",
       "          [[0, 0, 0, 0],\n",
       "           [0, 0, 0, 0],\n",
       "           [0, 0, 0, 0]],\n",
       "\n",
       "          [[0, 0, 0, 0],\n",
       "           [0, 0, 0, 0],\n",
       "           [0, 0, 0, 0]],\n",
       "\n",
       "          ...,\n",
       "\n",
       "          [[0, 0, 0, 0],\n",
       "           [0, 0, 0, 0],\n",
       "           [0, 0, 0, 0]],\n",
       "\n",
       "          [[0, 0, 0, 0],\n",
       "           [0, 0, 0, 0],\n",
       "           [0, 0, 0, 0]],\n",
       "\n",
       "          [[0, 0, 0, 0],\n",
       "           [0, 0, 0, 0],\n",
       "           [0, 0, 0, 0]]],\n",
       "\n",
       "\n",
       "         [[[0, 0, 0, 0],\n",
       "           [0, 0, 0, 0],\n",
       "           [0, 0, 0, 0]],\n",
       "\n",
       "          [[0, 0, 0, 0],\n",
       "           [0, 0, 0, 0],\n",
       "           [0, 0, 0, 0]],\n",
       "\n",
       "          [[0, 0, 0, 0],\n",
       "           [0, 0, 0, 0],\n",
       "           [0, 0, 0, 0]],\n",
       "\n",
       "          ...,\n",
       "\n",
       "          [[0, 0, 0, 0],\n",
       "           [0, 0, 0, 0],\n",
       "           [0, 0, 0, 0]],\n",
       "\n",
       "          [[0, 0, 0, 0],\n",
       "           [0, 0, 0, 0],\n",
       "           [0, 0, 0, 0]],\n",
       "\n",
       "          [[0, 0, 0, 0],\n",
       "           [0, 0, 0, 0],\n",
       "           [0, 0, 0, 0]]],\n",
       "\n",
       "\n",
       "         [[[0, 0, 0, 0],\n",
       "           [0, 0, 0, 0],\n",
       "           [0, 0, 0, 0]],\n",
       "\n",
       "          [[0, 0, 0, 0],\n",
       "           [0, 0, 0, 0],\n",
       "           [0, 0, 0, 0]],\n",
       "\n",
       "          [[0, 0, 0, 0],\n",
       "           [0, 0, 0, 0],\n",
       "           [0, 0, 0, 0]],\n",
       "\n",
       "          ...,\n",
       "\n",
       "          [[0, 0, 0, 0],\n",
       "           [0, 0, 0, 0],\n",
       "           [0, 0, 0, 0]],\n",
       "\n",
       "          [[0, 0, 0, 0],\n",
       "           [0, 0, 0, 0],\n",
       "           [0, 0, 0, 0]],\n",
       "\n",
       "          [[0, 0, 0, 0],\n",
       "           [0, 0, 0, 0],\n",
       "           [0, 0, 0, 0]]],\n",
       "\n",
       "\n",
       "         [[[0, 0, 0, 0],\n",
       "           [0, 0, 0, 0],\n",
       "           [0, 0, 0, 0]],\n",
       "\n",
       "          [[0, 0, 0, 0],\n",
       "           [0, 0, 0, 0],\n",
       "           [0, 0, 0, 0]],\n",
       "\n",
       "          [[0, 0, 0, 0],\n",
       "           [0, 0, 0, 0],\n",
       "           [0, 0, 0, 0]],\n",
       "\n",
       "          ...,\n",
       "\n",
       "          [[0, 0, 0, 0],\n",
       "           [0, 0, 0, 0],\n",
       "           [0, 0, 0, 0]],\n",
       "\n",
       "          [[0, 0, 0, 0],\n",
       "           [0, 0, 0, 0],\n",
       "           [0, 0, 0, 0]],\n",
       "\n",
       "          [[0, 0, 0, 0],\n",
       "           [0, 0, 0, 0],\n",
       "           [0, 0, 0, 0]]],\n",
       "\n",
       "\n",
       "         [[[0, 0, 0, 0],\n",
       "           [0, 0, 0, 0],\n",
       "           [0, 0, 0, 0]],\n",
       "\n",
       "          [[0, 0, 0, 0],\n",
       "           [0, 0, 0, 0],\n",
       "           [0, 0, 0, 0]],\n",
       "\n",
       "          [[0, 0, 0, 0],\n",
       "           [0, 0, 0, 0],\n",
       "           [0, 0, 0, 0]],\n",
       "\n",
       "          ...,\n",
       "\n",
       "          [[0, 0, 0, 0],\n",
       "           [0, 0, 0, 0],\n",
       "           [0, 0, 0, 0]],\n",
       "\n",
       "          [[0, 0, 0, 0],\n",
       "           [0, 0, 0, 0],\n",
       "           [0, 0, 0, 0]],\n",
       "\n",
       "          [[0, 0, 0, 0],\n",
       "           [0, 0, 0, 0],\n",
       "           [0, 0, 0, 0]]],\n",
       "\n",
       "\n",
       "         [[[0, 0, 0, 0],\n",
       "           [0, 0, 0, 0],\n",
       "           [0, 0, 0, 0]],\n",
       "\n",
       "          [[0, 0, 0, 0],\n",
       "           [0, 0, 0, 0],\n",
       "           [0, 0, 0, 0]],\n",
       "\n",
       "          [[0, 0, 0, 0],\n",
       "           [0, 0, 0, 0],\n",
       "           [0, 0, 0, 0]],\n",
       "\n",
       "          ...,\n",
       "\n",
       "          [[0, 0, 0, 0],\n",
       "           [0, 0, 0, 0],\n",
       "           [0, 0, 0, 0]],\n",
       "\n",
       "          [[0, 0, 0, 0],\n",
       "           [0, 0, 0, 0],\n",
       "           [0, 0, 0, 0]],\n",
       "\n",
       "          [[0, 0, 0, 0],\n",
       "           [0, 0, 0, 0],\n",
       "           [0, 0, 0, 0]]]],\n",
       "\n",
       "\n",
       "\n",
       "        [[[[0, 0, 0, 0],\n",
       "           [0, 0, 0, 0],\n",
       "           [0, 0, 0, 0]],\n",
       "\n",
       "          [[0, 0, 0, 0],\n",
       "           [0, 0, 0, 0],\n",
       "           [0, 0, 0, 0]],\n",
       "\n",
       "          [[0, 0, 0, 0],\n",
       "           [0, 0, 0, 0],\n",
       "           [0, 0, 0, 0]],\n",
       "\n",
       "          ...,\n",
       "\n",
       "          [[0, 0, 0, 0],\n",
       "           [0, 0, 0, 0],\n",
       "           [0, 0, 0, 0]],\n",
       "\n",
       "          [[0, 0, 0, 0],\n",
       "           [0, 0, 0, 0],\n",
       "           [0, 0, 0, 0]],\n",
       "\n",
       "          [[0, 0, 0, 0],\n",
       "           [0, 0, 0, 0],\n",
       "           [0, 0, 0, 0]]],\n",
       "\n",
       "\n",
       "         [[[0, 0, 0, 0],\n",
       "           [0, 0, 0, 0],\n",
       "           [0, 0, 0, 0]],\n",
       "\n",
       "          [[0, 0, 0, 0],\n",
       "           [0, 0, 0, 0],\n",
       "           [0, 0, 0, 0]],\n",
       "\n",
       "          [[0, 0, 0, 0],\n",
       "           [0, 0, 0, 0],\n",
       "           [0, 0, 0, 0]],\n",
       "\n",
       "          ...,\n",
       "\n",
       "          [[0, 0, 0, 0],\n",
       "           [0, 0, 0, 0],\n",
       "           [0, 0, 0, 0]],\n",
       "\n",
       "          [[0, 0, 0, 0],\n",
       "           [0, 0, 0, 0],\n",
       "           [0, 0, 0, 0]],\n",
       "\n",
       "          [[0, 0, 0, 0],\n",
       "           [0, 0, 0, 0],\n",
       "           [0, 0, 0, 0]]],\n",
       "\n",
       "\n",
       "         [[[0, 0, 0, 0],\n",
       "           [0, 0, 0, 0],\n",
       "           [0, 0, 0, 0]],\n",
       "\n",
       "          [[0, 0, 0, 0],\n",
       "           [0, 0, 0, 0],\n",
       "           [0, 0, 0, 0]],\n",
       "\n",
       "          [[0, 0, 0, 0],\n",
       "           [0, 0, 0, 0],\n",
       "           [0, 0, 0, 0]],\n",
       "\n",
       "          ...,\n",
       "\n",
       "          [[0, 0, 0, 0],\n",
       "           [0, 0, 0, 0],\n",
       "           [0, 0, 0, 0]],\n",
       "\n",
       "          [[0, 0, 0, 0],\n",
       "           [0, 0, 0, 0],\n",
       "           [0, 0, 0, 0]],\n",
       "\n",
       "          [[0, 0, 0, 0],\n",
       "           [0, 0, 0, 0],\n",
       "           [0, 0, 0, 0]]],\n",
       "\n",
       "\n",
       "         [[[0, 0, 0, 0],\n",
       "           [0, 0, 0, 0],\n",
       "           [0, 0, 0, 0]],\n",
       "\n",
       "          [[0, 0, 0, 0],\n",
       "           [0, 0, 0, 0],\n",
       "           [0, 0, 0, 0]],\n",
       "\n",
       "          [[0, 0, 0, 0],\n",
       "           [0, 0, 0, 0],\n",
       "           [0, 0, 0, 0]],\n",
       "\n",
       "          ...,\n",
       "\n",
       "          [[0, 0, 0, 0],\n",
       "           [0, 0, 0, 0],\n",
       "           [0, 0, 0, 0]],\n",
       "\n",
       "          [[0, 0, 0, 0],\n",
       "           [0, 0, 0, 0],\n",
       "           [0, 0, 0, 0]],\n",
       "\n",
       "          [[0, 0, 0, 0],\n",
       "           [0, 0, 0, 0],\n",
       "           [0, 0, 0, 0]]],\n",
       "\n",
       "\n",
       "         [[[0, 0, 0, 0],\n",
       "           [0, 0, 0, 0],\n",
       "           [0, 0, 0, 0]],\n",
       "\n",
       "          [[0, 0, 0, 0],\n",
       "           [0, 0, 0, 0],\n",
       "           [0, 0, 0, 0]],\n",
       "\n",
       "          [[0, 0, 0, 0],\n",
       "           [0, 0, 0, 0],\n",
       "           [0, 0, 0, 0]],\n",
       "\n",
       "          ...,\n",
       "\n",
       "          [[0, 0, 0, 0],\n",
       "           [0, 0, 0, 0],\n",
       "           [0, 0, 0, 0]],\n",
       "\n",
       "          [[0, 0, 0, 0],\n",
       "           [0, 0, 0, 0],\n",
       "           [0, 0, 0, 0]],\n",
       "\n",
       "          [[0, 0, 0, 0],\n",
       "           [0, 0, 0, 0],\n",
       "           [0, 0, 0, 0]]],\n",
       "\n",
       "\n",
       "         [[[0, 0, 0, 0],\n",
       "           [0, 0, 0, 0],\n",
       "           [0, 0, 0, 0]],\n",
       "\n",
       "          [[0, 0, 0, 0],\n",
       "           [0, 0, 0, 0],\n",
       "           [0, 0, 0, 0]],\n",
       "\n",
       "          [[0, 0, 0, 0],\n",
       "           [0, 0, 0, 0],\n",
       "           [0, 0, 0, 0]],\n",
       "\n",
       "          ...,\n",
       "\n",
       "          [[0, 0, 0, 0],\n",
       "           [0, 0, 0, 0],\n",
       "           [0, 0, 0, 0]],\n",
       "\n",
       "          [[0, 0, 0, 0],\n",
       "           [0, 0, 0, 0],\n",
       "           [0, 0, 0, 0]],\n",
       "\n",
       "          [[0, 0, 0, 0],\n",
       "           [0, 0, 0, 0],\n",
       "           [0, 0, 0, 0]]]]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_mask = torch.zeros((2,3,3,1), dtype = torch.int64)\n",
    "\n",
    "grid_mask + i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[[  0,   1,   2,   3]],\n",
       "\n",
       "          [[ 20,  21,  22,  23]],\n",
       "\n",
       "          [[ 40,  41,  42,  43]]],\n",
       "\n",
       "\n",
       "         [[[ 60,  61,  62,  63]],\n",
       "\n",
       "          [[ 80,  81,  82,  83]],\n",
       "\n",
       "          [[100, 101, 102, 103]]],\n",
       "\n",
       "\n",
       "         [[[120, 121, 122, 123]],\n",
       "\n",
       "          [[140, 141, 142, 143]],\n",
       "\n",
       "          [[160, 161, 162, 163]]]],\n",
       "\n",
       "\n",
       "\n",
       "        [[[[180, 181, 182, 183]],\n",
       "\n",
       "          [[200, 201, 202, 203]],\n",
       "\n",
       "          [[220, 221, 222, 223]]],\n",
       "\n",
       "\n",
       "         [[[240, 241, 242, 243]],\n",
       "\n",
       "          [[260, 261, 262, 263]],\n",
       "\n",
       "          [[280, 281, 282, 283]]],\n",
       "\n",
       "\n",
       "         [[[300, 301, 302, 303]],\n",
       "\n",
       "          [[320, 321, 322, 323]],\n",
       "\n",
       "          [[340, 341, 342, 343]]]]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.gather(grid, -2, grid_mask.unsqueeze(-1).repeat(1,1,1,1,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[  0,   1,   2,   3],\n",
       "          [ 20,  21,  22,  23],\n",
       "          [ 40,  41,  42,  43]],\n",
       "\n",
       "         [[ 60,  61,  62,  63],\n",
       "          [ 80,  81,  82,  83],\n",
       "          [100, 101, 102, 103]],\n",
       "\n",
       "         [[120, 121, 122, 123],\n",
       "          [140, 141, 142, 143],\n",
       "          [160, 161, 162, 163]]],\n",
       "\n",
       "\n",
       "        [[[180, 181, 182, 183],\n",
       "          [200, 201, 202, 203],\n",
       "          [220, 221, 222, 223]],\n",
       "\n",
       "         [[240, 241, 242, 243],\n",
       "          [260, 261, 262, 263],\n",
       "          [280, 281, 282, 283]],\n",
       "\n",
       "         [[300, 301, 302, 303],\n",
       "          [320, 321, 322, 323],\n",
       "          [340, 341, 342, 343]]]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid[..., 0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "numgrid = 7\n",
    "\n",
    "x = torch.arange(numgrid)\n",
    "y = torch.arange(numgrid)\n",
    "\n",
    "grid_y, grid_x = torch.meshgrid(x,y, indexing = 'ij')\n",
    "grid_x = grid_x.expand(8, -1,-1)#.unsqueeze(-1)\n",
    "grid_y = grid_y.expand(8, -1,-1)#.unsqueeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (8) must match the size of tensor b (7) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[147], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m grid_x \u001b[39m*\u001b[39;49m torch\u001b[39m.\u001b[39;49mrandn(\u001b[39m8\u001b[39;49m,\u001b[39m7\u001b[39;49m,\u001b[39m7\u001b[39;49m,\u001b[39m1\u001b[39;49m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The size of tensor a (8) must match the size of tensor b (7) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "grid_x * torch.randn(8,7,7,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "box1s = labelgrid[..., 0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = torch.nn.MSELoss()\n",
    "inp = torch.randn((16,13,13, 1))\n",
    "target = torch.randn((16,13,13, 1))\n",
    "output = loss(inp, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.9788)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[15, 25],\n",
       "        [35, 45]])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ls = torch.tensor([[10, 15],[20, 25],[30, 35],[40, 45],[50, 55]])\n",
    "h = ls[:,0]\n",
    "w = ls[:,1]\n",
    "\n",
    "\n",
    "value = torch.tensor([[0,1],\n",
    "                      [2,3]])\n",
    "\n",
    "torch.take(w, value)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = torch.arange(5).repeat(1,5).reshape(5,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3.1623, 3.8730, 4.4721, 5.0000, 5.4772],\n",
       "        [3.1623, 3.8730, 4.4721, 5.0000, 5.4772],\n",
       "        [3.1623, 3.8730, 4.4721, 5.0000, 5.4772],\n",
       "        [3.1623, 3.8730, 4.4721, 5.0000, 5.4772],\n",
       "        [3.1623, 3.8730, 4.4721, 5.0000, 5.4772]])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sqrt(torch.take(ls, indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (5) must match the size of tensor b (7) at non-singleton dimension 3",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[109], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m (torch\u001b[39m.\u001b[39;49mzeros((\u001b[39m8\u001b[39;49m,\u001b[39m7\u001b[39;49m,\u001b[39m7\u001b[39;49m,\u001b[39m5\u001b[39;49m,\u001b[39m1\u001b[39;49m)) \u001b[39m*\u001b[39;49m torch\u001b[39m.\u001b[39;49mrandn((\u001b[39m8\u001b[39;49m,\u001b[39m7\u001b[39;49m,\u001b[39m7\u001b[39;49m,\u001b[39m5\u001b[39;49m)))\u001b[39m.\u001b[39mshape\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The size of tensor a (5) must match the size of tensor b (7) at non-singleton dimension 3"
     ]
    }
   ],
   "source": [
    "(torch.zeros((8,7,7,5,1)) * torch.randn((8,7,7,5))).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "\n",
    "model_paths = {\n",
    "    'darknet19': 'https://s3.ap-northeast-2.amazonaws.com/deepbaksuvision/darknet19-deepBakSu-e1b3ec1e.pth'\n",
    "}\n",
    "\n",
    "class GlobalAvgPool2d(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GlobalAvgPool2d, self).__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        N = x.data.size(0)\n",
    "        C = x.data.size(1)\n",
    "        H = x.data.size(2)\n",
    "        W = x.data.size(3)\n",
    "        x = F.avg_pool2d(x, (H, W))\n",
    "        x = x.view(N, C)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Darknet19(nn.Module):\n",
    "    def __init__(self, pretrained=True):\n",
    "        super(Darknet19, self).__init__()\n",
    "\n",
    "        self.features = nn.Sequential(OrderedDict([\n",
    "        ('layer1', nn.Sequential(OrderedDict([\n",
    "            ('conv1_1', nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1, bias=False)),\n",
    "            ('bn1_1', nn.BatchNorm2d(32)),\n",
    "            ('leaky1_1', nn.LeakyReLU(0.1, inplace=True)),\n",
    "            ('maxpool1', nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        ]))),\n",
    "        ('layer2', nn.Sequential(OrderedDict([\n",
    "            ('conv2_1', nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1, bias=False)),\n",
    "            ('bn2_1', nn.BatchNorm2d(64)),\n",
    "            ('leaky2_1', nn.LeakyReLU(0.1, inplace=True)),\n",
    "            ('maxpool2', nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        ]))),\n",
    "        ('layer3', nn.Sequential(OrderedDict([\n",
    "            ('conv3_1', nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1, bias=False)),\n",
    "            ('bn3_1', nn.BatchNorm2d(128)),\n",
    "            ('leaky3_1', nn.LeakyReLU(0.1, inplace=True)),\n",
    "            ('conv3_2', nn.Conv2d(128, 64, kernel_size=1, stride=1, padding=0, bias=False)),\n",
    "            ('bn3_2', nn.BatchNorm2d(64)),\n",
    "            ('leaky3_2', nn.LeakyReLU(0.1, inplace=True)),\n",
    "            ('conv3_3', nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1, bias=False)),\n",
    "            ('bn3_3', nn.BatchNorm2d(128)),\n",
    "            ('leaky3_3', nn.LeakyReLU(0.1, inplace=True)),\n",
    "            ('maxpool3', nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        ]))),\n",
    "        ('layer4', nn.Sequential(OrderedDict([\n",
    "            ('conv4_1', nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1, bias=False)),\n",
    "            ('bn4_1', nn.BatchNorm2d(256)),\n",
    "            ('leaky4_1', nn.LeakyReLU(0.1, inplace=True)),\n",
    "            ('conv4_2', nn.Conv2d(256, 128, kernel_size=1, stride=1, padding=0, bias=False)),\n",
    "            ('bn4_2', nn.BatchNorm2d(128)),\n",
    "            ('leaky4_2', nn.LeakyReLU(0.1, inplace=True)),\n",
    "            ('conv4_3', nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1, bias=False)),\n",
    "            ('bn4_3', nn.BatchNorm2d(256)),\n",
    "            ('leaky4_3', nn.LeakyReLU(0.1, inplace=True)),\n",
    "            ('maxpool4', nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        ]))),\n",
    "        ('layer5', nn.Sequential(OrderedDict([\n",
    "            ('conv5_1', nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1, bias=False)),\n",
    "            ('bn5_1', nn.BatchNorm2d(512)),\n",
    "            ('leaky5_1', nn.LeakyReLU(0.1, inplace=True)),\n",
    "            ('conv5_2', nn.Conv2d(512, 256, kernel_size=1, stride=1, padding=0, bias=False)),\n",
    "            ('bn5_2', nn.BatchNorm2d(256)),\n",
    "            ('leaky5_2', nn.LeakyReLU(0.1, inplace=True)),\n",
    "            ('conv5_3', nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1, bias=False)),\n",
    "            ('bn5_3', nn.BatchNorm2d(512)),\n",
    "            ('leaky5_3', nn.LeakyReLU(0.1, inplace=True)),\n",
    "            ('conv5_4', nn.Conv2d(512, 256, kernel_size=1, stride=1, padding=1, bias=False)),\n",
    "            ('bn5_4', nn.BatchNorm2d(256)),\n",
    "            ('leaky5_4', nn.LeakyReLU(0.1, inplace=True)),\n",
    "            ('conv5_5', nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1, bias=False)),\n",
    "            ('bn5_5', nn.BatchNorm2d(512)),\n",
    "            ('leaky5_5', nn.LeakyReLU(0.1, inplace=True)),\n",
    "            ('maxpool5', nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        ]))),\n",
    "        ('layer6', nn.Sequential(OrderedDict([\n",
    "            ('conv6_1', nn.Conv2d(512, 1024, kernel_size=3, stride=1, padding=1, bias=False)),\n",
    "            ('bn6_1', nn.BatchNorm2d(1024)),\n",
    "            ('leaky6_1', nn.LeakyReLU(0.1, inplace=True)),\n",
    "            ('conv6_2', nn.Conv2d(1024, 512, kernel_size=1, stride=1, padding=0, bias=False)),\n",
    "            ('bn6_2', nn.BatchNorm2d(512)),\n",
    "            ('leaky6_2', nn.LeakyReLU(0.1, inplace=True)),\n",
    "            ('conv6_3', nn.Conv2d(512, 1024, kernel_size=3, stride=1, padding=1, bias=False)),\n",
    "            ('bn6_3', nn.BatchNorm2d(1024)),\n",
    "            ('leaky6_3', nn.LeakyReLU(0.1, inplace=True)),\n",
    "            ('conv6_4', nn.Conv2d(1024, 512, kernel_size=1, stride=1, padding=1, bias=False)),\n",
    "            ('bn6_4', nn.BatchNorm2d(512)),\n",
    "            ('leaky6_4', nn.LeakyReLU(0.1, inplace=True)),\n",
    "            ('conv6_5', nn.Conv2d(512, 1024, kernel_size=3, stride=1, padding=1, bias=False)),\n",
    "            ('bn6_5', nn.BatchNorm2d(1024)),\n",
    "            ('leaky6_5', nn.LeakyReLU(0.1, inplace=True))\n",
    "        ])))\n",
    "        ]))\n",
    "\n",
    "        self.classifier = nn.Sequential(OrderedDict([\n",
    "        ('conv7_1', nn.Conv2d(1024, 1000, kernel_size=(1, 1), stride=(1, 1))),\n",
    "        ('globalavgpool', GlobalAvgPool2d()),\n",
    "        ('softmax', nn.Softmax(dim=1))\n",
    "        ]))\n",
    "\n",
    "        # if pretrained:\n",
    "        #     self.load_state_dict(model_zoo.load_url(model_paths['darknet19'],  progress=True))\n",
    "        #     print('Model is loaded')\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.features :\n",
    "            print(layer)\n",
    "            print('.')\n",
    "        # out = self.features(x)\n",
    "        # out = self.classifier(out)\n",
    "        # return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Darknet19()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (conv1_1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn1_1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky1_1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "  (maxpool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      ")\n",
      ".\n",
      "Sequential(\n",
      "  (conv2_1): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2_1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky2_1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "  (maxpool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      ")\n",
      ".\n",
      "Sequential(\n",
      "  (conv3_1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn3_1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky3_1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "  (conv3_2): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn3_2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky3_2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "  (conv3_3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn3_3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky3_3): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "  (maxpool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      ")\n",
      ".\n",
      "Sequential(\n",
      "  (conv4_1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn4_1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky4_1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "  (conv4_2): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn4_2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky4_2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "  (conv4_3): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn4_3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky4_3): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "  (maxpool4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      ")\n",
      ".\n",
      "Sequential(\n",
      "  (conv5_1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn5_1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky5_1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "  (conv5_2): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn5_2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky5_2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "  (conv5_3): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn5_3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky5_3): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "  (conv5_4): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn5_4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky5_4): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "  (conv5_5): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn5_5): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky5_5): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "  (maxpool5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      ")\n",
      ".\n",
      "Sequential(\n",
      "  (conv6_1): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn6_1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky6_1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "  (conv6_2): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn6_2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky6_2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "  (conv6_3): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn6_3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky6_3): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "  (conv6_4): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn6_4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky6_4): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "  (conv6_5): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn6_5): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky6_5): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      ")\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "model(torch.rand(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 7, 7, 5])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros_like(torch.randn((8,7,7,5,24))[...,0]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "a = torch.tensor([1]).numpy().item()\n",
    "\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.maximum(torch.tensor([1,2,3]), torch.tensor([1,2,3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IoU(box1, box2) :\n",
    "    # box = [x,y,w,h]\n",
    "\n",
    "    def box_area(box) :\n",
    "        return box[2] * box[3]\n",
    "    \n",
    "    box1_area = box_area(box1.T)\n",
    "    box2_area = box_area(box2.T)\n",
    "\n",
    "    box1_w = box1[..., 2:3]\n",
    "    box1_h = box1[..., 3:4]\n",
    "    box2_w = box2[..., 2:3]\n",
    "    box2_h = box2[..., 3:4]\n",
    "    box1_xmin = box1[..., 0:1] - box1_w / 2\n",
    "    box1_ymin = box1[..., 1:2] - box1_h / 2\n",
    "    box1_xmax = box1[..., 0:1] + box1_w / 2\n",
    "    box1_ymax = box1[..., 1:2] + box1_w / 2\n",
    "\n",
    "    box2_xmin = box2[..., 0:1] - box2_w / 2\n",
    "    box2_ymin = box2[..., 1:2] - box2_h / 2\n",
    "    box2_xmax = box2[..., 0:1] + box2_w / 2\n",
    "    box2_ymax = box2[..., 1:2] + box2_w / 2\n",
    "    \n",
    "    box1_topleft = torch.cat([box1_xmin, box1_ymin], axis = -1)\n",
    "    box2_topleft = torch.cat([box2_xmin, box2_ymin], axis = -1)\n",
    "\n",
    "    box1_bottomright = torch.cat([box1_xmax, box1_ymax], axis = -1)\n",
    "    box2_bottomright = torch.cat([box2_xmax, box2_ymax], axis = -1)\n",
    "\n",
    "    top_left = torch.max(box1_topleft[:,None, :], box2_topleft)\n",
    "    bottom_right = torch.min(box1_bottomright[:, None, :], box2_bottomright)\n",
    "\n",
    "\n",
    "\n",
    "    area_inter = torch.prod(\n",
    "        torch.clip(bottom_right - top_left, min = 0 , max = None), -1)\n",
    "\n",
    "    return area_inter / (box1_area[:, None] + box2_area - area_inter + 1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\Desktop\\projects\\object_detection\\./YOLOv2\\loss.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.register_buffer('anchorbox', torch.tensor(anchorbox))\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('./YOLOv2')\n",
    "from YOLOv2.model import Yolov2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\Desktop\\projects\\object_detection\\./YOLOv2\\loss.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.register_buffer('anchorbox', torch.tensor(anchorbox))\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for Yolov2:\n\tWhile copying the parameter named \"yolo_loss.grid_x\", whose dimensions in the model are torch.Size([13, 13]) and whose dimensions in the checkpoint are torch.Size([13, 13]), an exception occurred : ('unsupported operation: more than one element of the written-to tensor refers to a single memory location. Please clone() the tensor before performing the operation.',).\n\tWhile copying the parameter named \"yolo_loss.grid_y\", whose dimensions in the model are torch.Size([13, 13]) and whose dimensions in the checkpoint are torch.Size([13, 13]), an exception occurred : ('unsupported operation: more than one element of the written-to tensor refers to a single memory location. Please clone() the tensor before performing the operation.',).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model\u001b[39m.\u001b[39;49mload_from_checkpoint(in_channels \u001b[39m=\u001b[39;49m \u001b[39m3\u001b[39;49m, anchorbox \u001b[39m=\u001b[39;49m [[\u001b[39m0.57273\u001b[39;49m, \u001b[39m0.677385\u001b[39;49m], [\u001b[39m1.87446\u001b[39;49m, \u001b[39m2.06253\u001b[39;49m], [\u001b[39m3.33843\u001b[39;49m, \u001b[39m5.47434\u001b[39;49m], [\u001b[39m7.88282\u001b[39;49m, \u001b[39m3.52778\u001b[39;49m], [\u001b[39m9.77052\u001b[39;49m, \u001b[39m9.16828\u001b[39;49m]], num_grid \u001b[39m=\u001b[39;49m \u001b[39m13\u001b[39;49m, num_classes \u001b[39m=\u001b[39;49m \u001b[39m13\u001b[39;49m,\n\u001b[0;32m      2\u001b[0m             checkpoint_path \u001b[39m=\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39mYOLOv2/outputs/2023-04-16/12-36-28/tensorboard/yolov2-epoch=72-val_loss=3863.54.ckpt\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pytorch_lightning\\core\\saving.py:137\u001b[0m, in \u001b[0;36mModelIO.load_from_checkpoint\u001b[1;34m(cls, checkpoint_path, map_location, hparams_file, strict, **kwargs)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[0;32m     58\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload_from_checkpoint\u001b[39m(\n\u001b[0;32m     59\u001b[0m     \u001b[39mcls\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     64\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any,\n\u001b[0;32m     65\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Self:  \u001b[39m# type: ignore[valid-type]\u001b[39;00m\n\u001b[0;32m     66\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     67\u001b[0m \u001b[39m    Primary way of loading a model from a checkpoint. When Lightning saves a checkpoint\u001b[39;00m\n\u001b[0;32m     68\u001b[0m \u001b[39m    it stores the arguments passed to ``__init__``  in the checkpoint under ``\"hyper_parameters\"``.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[39m        y_hat = pretrained_model(x)\u001b[39;00m\n\u001b[0;32m    136\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 137\u001b[0m     \u001b[39mreturn\u001b[39;00m _load_from_checkpoint(\n\u001b[0;32m    138\u001b[0m         \u001b[39mcls\u001b[39m,\n\u001b[0;32m    139\u001b[0m         checkpoint_path,\n\u001b[0;32m    140\u001b[0m         map_location,\n\u001b[0;32m    141\u001b[0m         hparams_file,\n\u001b[0;32m    142\u001b[0m         strict,\n\u001b[0;32m    143\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m    144\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pytorch_lightning\\core\\saving.py:180\u001b[0m, in \u001b[0;36m_load_from_checkpoint\u001b[1;34m(cls, checkpoint_path, map_location, hparams_file, strict, **kwargs)\u001b[0m\n\u001b[0;32m    178\u001b[0m     \u001b[39mreturn\u001b[39;00m _load_state(\u001b[39mcls\u001b[39m, checkpoint, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    179\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39missubclass\u001b[39m(\u001b[39mcls\u001b[39m, pl\u001b[39m.\u001b[39mLightningModule):\n\u001b[1;32m--> 180\u001b[0m     \u001b[39mreturn\u001b[39;00m _load_state(\u001b[39mcls\u001b[39m, checkpoint, strict\u001b[39m=\u001b[39mstrict, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    181\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUnsupported \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mcls\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pytorch_lightning\\core\\saving.py:238\u001b[0m, in \u001b[0;36m_load_state\u001b[1;34m(cls, checkpoint, strict, **cls_kwargs_new)\u001b[0m\n\u001b[0;32m    236\u001b[0m \u001b[39m# load the state_dict on the model automatically\u001b[39;00m\n\u001b[0;32m    237\u001b[0m \u001b[39massert\u001b[39;00m strict \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m--> 238\u001b[0m keys \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39;49mload_state_dict(checkpoint[\u001b[39m\"\u001b[39;49m\u001b[39mstate_dict\u001b[39;49m\u001b[39m\"\u001b[39;49m], strict\u001b[39m=\u001b[39;49mstrict)\n\u001b[0;32m    240\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m strict:\n\u001b[0;32m    241\u001b[0m     \u001b[39mif\u001b[39;00m keys\u001b[39m.\u001b[39mmissing_keys:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\module.py:2041\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[1;34m(self, state_dict, strict)\u001b[0m\n\u001b[0;32m   2036\u001b[0m         error_msgs\u001b[39m.\u001b[39minsert(\n\u001b[0;32m   2037\u001b[0m             \u001b[39m0\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mMissing key(s) in state_dict: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m   2038\u001b[0m                 \u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(k) \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m missing_keys)))\n\u001b[0;32m   2040\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(error_msgs) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m-> 2041\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mError(s) in loading state_dict for \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m   2042\u001b[0m                        \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(error_msgs)))\n\u001b[0;32m   2043\u001b[0m \u001b[39mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for Yolov2:\n\tWhile copying the parameter named \"yolo_loss.grid_x\", whose dimensions in the model are torch.Size([13, 13]) and whose dimensions in the checkpoint are torch.Size([13, 13]), an exception occurred : ('unsupported operation: more than one element of the written-to tensor refers to a single memory location. Please clone() the tensor before performing the operation.',).\n\tWhile copying the parameter named \"yolo_loss.grid_y\", whose dimensions in the model are torch.Size([13, 13]) and whose dimensions in the checkpoint are torch.Size([13, 13]), an exception occurred : ('unsupported operation: more than one element of the written-to tensor refers to a single memory location. Please clone() the tensor before performing the operation.',)."
     ]
    }
   ],
   "source": [
    "model.load_from_checkpoint(in_channels = 3, anchorbox = [[0.57273, 0.677385], [1.87446, 2.06253], [3.33843, 5.47434], [7.88282, 3.52778], [9.77052, 9.16828]], num_grid = 13, num_classes = 13,\n",
    "            checkpoint_path = 'YOLOv2/outputs/2023-04-16/12-36-28/tensorboard/yolov2-epoch=72-val_loss=3863.54.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\Desktop\\projects\\object_detection\\./YOLOv2\\loss.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.register_buffer('anchorbox', torch.tensor(anchorbox))\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for Yolov2:\n\tWhile copying the parameter named \"yolo_loss.grid_x\", whose dimensions in the model are torch.Size([13, 13]) and whose dimensions in the checkpoint are torch.Size([13, 13]), an exception occurred : ('unsupported operation: more than one element of the written-to tensor refers to a single memory location. Please clone() the tensor before performing the operation.',).\n\tWhile copying the parameter named \"yolo_loss.grid_y\", whose dimensions in the model are torch.Size([13, 13]) and whose dimensions in the checkpoint are torch.Size([13, 13]), an exception occurred : ('unsupported operation: more than one element of the written-to tensor refers to a single memory location. Please clone() the tensor before performing the operation.',).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 9\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[39m# model.yolo_loss.grid_x = model.yolo_loss.grid_x.contiguous()\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[39m# model.yolo_loss.grid_y = model.yolo_loss.grid_y.contiguous()\u001b[39;00m\n\u001b[0;32m      8\u001b[0m weight \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mload(\u001b[39m'\u001b[39m\u001b[39mYOLOv2/outputs/2023-04-16/12-36-28/tensorboard/yolov2-epoch=72-val_loss=3863.54.ckpt\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m----> 9\u001b[0m model\u001b[39m.\u001b[39;49mload_state_dict(weight[\u001b[39m'\u001b[39;49m\u001b[39mstate_dict\u001b[39;49m\u001b[39m'\u001b[39;49m])\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\module.py:2041\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[1;34m(self, state_dict, strict)\u001b[0m\n\u001b[0;32m   2036\u001b[0m         error_msgs\u001b[39m.\u001b[39minsert(\n\u001b[0;32m   2037\u001b[0m             \u001b[39m0\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mMissing key(s) in state_dict: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m   2038\u001b[0m                 \u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(k) \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m missing_keys)))\n\u001b[0;32m   2040\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(error_msgs) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m-> 2041\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mError(s) in loading state_dict for \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m   2042\u001b[0m                        \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(error_msgs)))\n\u001b[0;32m   2043\u001b[0m \u001b[39mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for Yolov2:\n\tWhile copying the parameter named \"yolo_loss.grid_x\", whose dimensions in the model are torch.Size([13, 13]) and whose dimensions in the checkpoint are torch.Size([13, 13]), an exception occurred : ('unsupported operation: more than one element of the written-to tensor refers to a single memory location. Please clone() the tensor before performing the operation.',).\n\tWhile copying the parameter named \"yolo_loss.grid_y\", whose dimensions in the model are torch.Size([13, 13]) and whose dimensions in the checkpoint are torch.Size([13, 13]), an exception occurred : ('unsupported operation: more than one element of the written-to tensor refers to a single memory location. Please clone() the tensor before performing the operation.',)."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "model = Yolov2(in_channels = 3, anchorbox = [[0.57273, 0.677385], [1.87446, 2.06253], [3.33843, 5.47434], [7.88282, 3.52778], [9.77052, 9.16828]], num_grid = 13, num_classes = 13)\n",
    "\n",
    "model.yolo_loss.grid_x = model.yolo_loss.grid_x.contiguous()\n",
    "model.yolo_loss.grid_y = model.yolo_loss.grid_y.contiguous()\n",
    "\n",
    "weight = torch.load('YOLOv2/outputs/2023-04-16/12-36-28/tensorboard/yolov2-epoch=72-val_loss=3863.54.ckpt')\n",
    "model.load_state_dict(weight['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages)\n",
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 23.0.1\n",
      "[notice] To update, run: C:\\Users\\user\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting hydra-core\n",
      "  Downloading hydra_core-1.3.2-py3-none-any.whl (154 kB)\n",
      "     -------------------------------------- 154.5/154.5 kB 9.0 MB/s eta 0:00:00\n",
      "Collecting antlr4-python3-runtime==4.9.*\n",
      "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
      "     -------------------------------------- 117.0/117.0 kB 6.7 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting omegaconf<2.4,>=2.2\n",
      "  Downloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
      "     ---------------------------------------- 79.5/79.5 kB ? eta 0:00:00\n",
      "Requirement already satisfied: packaging in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from hydra-core) (23.0)\n",
      "Requirement already satisfied: PyYAML>=5.1.0 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from omegaconf<2.4,>=2.2->hydra-core) (6.0)\n",
      "Building wheels for collected packages: antlr4-python3-runtime\n",
      "  Building wheel for antlr4-python3-runtime (setup.py): started\n",
      "  Building wheel for antlr4-python3-runtime (setup.py): finished with status 'done'\n",
      "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144578 sha256=0da2085491a6d9450add46c9e94525d78ec7272bd81250e788034e3c6bc6dca4\n",
      "  Stored in directory: c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local\\pip\\cache\\wheels\\48\\6a\\c2\\acb58c7afdf57e4cddf5e1513f5a2d62aa8e98f82a00c76d7c\n",
      "Successfully built antlr4-python3-runtime\n",
      "Installing collected packages: antlr4-python3-runtime, omegaconf, hydra-core\n",
      "Successfully installed antlr4-python3-runtime-4.9.3 hydra-core-1.3.2 omegaconf-2.3.0\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "BDDDataModule.__init__() missing 1 required positional argument: 'cfg'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m sys\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mappend(\u001b[39m'\u001b[39m\u001b[39mYOLOv2\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mYOLOv2\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m \u001b[39mimport\u001b[39;00m BDDDataModule\n\u001b[1;32m----> 7\u001b[0m BDDDataModule()\n",
      "\u001b[1;31mTypeError\u001b[0m: BDDDataModule.__init__() missing 1 required positional argument: 'cfg'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('YOLOv2')\n",
    "from YOLOv2.data import BDDDataModule\n",
    "\n",
    "BDDDataModule()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5032)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "inp = torch.tensor([1, 1, 1, 1]).float()\n",
    "target = torch.tensor([0, 1, 0, 1]).float()\n",
    "inp = inp * target\n",
    "\n",
    "loss(inp, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def kmean_anchors(path='./data/coco128.yaml', n=9, img_size=640, thr=4.0, gen=1000, verbose=True):\n",
    "    \"\"\" Creates kmeans-evolved anchors from training dataset\n",
    "        Arguments:\n",
    "            path: path to dataset *.yaml, or a loaded dataset\n",
    "            n: number of anchors\n",
    "            img_size: image size used for training\n",
    "            thr: anchor-label wh ratio threshold hyperparameter hyp['anchor_t'] used for training, default=4.0\n",
    "            gen: generations to evolve anchors using genetic algorithm\n",
    "            verbose: print all results\n",
    "        Return:\n",
    "            k: kmeans evolved anchors\n",
    "        Usage:\n",
    "            from utils.general import *; _ = kmean_anchors()\n",
    "    \"\"\"\n",
    "    thr = 1. / thr\n",
    "\n",
    "    def metric(k, wh):  # compute metrics\n",
    "        r = wh[:, None] / k[None]\n",
    "        x = torch.min(r, 1. / r).min(2)[0]  # ratio metric\n",
    "        # x = wh_iou(wh, torch.tensor(k))  # iou metric\n",
    "        return x, x.max(1)[0]  # x, best_x\n",
    "\n",
    "    def anchor_fitness(k):  # mutation fitness\n",
    "        _, best = metric(torch.tensor(k, dtype=torch.float32), wh)\n",
    "        return (best * (best > thr).float()).mean()  # fitness\n",
    "\n",
    "    def print_results(k):\n",
    "        k = k[np.argsort(k.prod(1))]  # sort small to large\n",
    "        x, best = metric(k, wh0)\n",
    "        bpr, aat = (best > thr).float().mean(), (x > thr).float().mean() * n  # best possible recall, anch > thr\n",
    "        print('thr=%.2f: %.4f best possible recall, %.2f anchors past thr' % (thr, bpr, aat))\n",
    "        print('n=%g, img_size=%s, metric_all=%.3f/%.3f-mean/best, past_thr=%.3f-mean: ' %\n",
    "              (n, img_size, x.mean(), best.mean(), x[x > thr].mean()), end='')\n",
    "        for i, x in enumerate(k):\n",
    "            print('%i,%i' % (round(x[0]), round(x[1])), end=',  ' if i < len(k) - 1 else '\\n')  # use in *.cfg\n",
    "        return k\n",
    "\n",
    "    if isinstance(path, str):  # *.yaml file\n",
    "        with open(path) as f:\n",
    "            data_dict = yaml.load(f, Loader=yaml.FullLoader)  # model dict\n",
    "        from utils.datasets import LoadImagesAndLabels\n",
    "        dataset = LoadImagesAndLabels(data_dict['train'], augment=True, rect=True)\n",
    "    else:\n",
    "        dataset = path  # dataset\n",
    "\n",
    "    # Get label wh\n",
    "    shapes = img_size * dataset.shapes / dataset.shapes.max(1, keepdims=True)\n",
    "    wh0 = np.concatenate([l[:, 3:5] * s for s, l in zip(shapes, dataset.labels)])  # wh\n",
    "\n",
    "    # Filter\n",
    "    i = (wh0 < 3.0).any(1).sum()\n",
    "    if i:\n",
    "        print('WARNING: Extremely small objects found. '\n",
    "              '%g of %g labels are < 3 pixels in width or height.' % (i, len(wh0)))\n",
    "    wh = wh0[(wh0 >= 2.0).any(1)]  # filter > 2 pixels\n",
    "\n",
    "    # Kmeans calculation\n",
    "    print('Running kmeans for %g anchors on %g points...' % (n, len(wh)))\n",
    "    s = wh.std(0)  # sigmas for whitening\n",
    "    k, dist = kmeans(wh / s, n, iter=30)  # points, mean distance\n",
    "    k *= s\n",
    "    wh = torch.tensor(wh, dtype=torch.float32)  # filtered\n",
    "    wh0 = torch.tensor(wh0, dtype=torch.float32)  # unfiltered\n",
    "    k = print_results(k)\n",
    "\n",
    "    # Plot\n",
    "    # k, d = [None] * 20, [None] * 20\n",
    "    # for i in tqdm(range(1, 21)):\n",
    "    #     k[i-1], d[i-1] = kmeans(wh / s, i)  # points, mean distance\n",
    "    # fig, ax = plt.subplots(1, 2, figsize=(14, 7))\n",
    "    # ax = ax.ravel()\n",
    "    # ax[0].plot(np.arange(1, 21), np.array(d) ** 2, marker='.')\n",
    "    # fig, ax = plt.subplots(1, 2, figsize=(14, 7))  # plot wh\n",
    "    # ax[0].hist(wh[wh[:, 0]<100, 0],400)\n",
    "    # ax[1].hist(wh[wh[:, 1]<100, 1],400)\n",
    "    # fig.tight_layout()\n",
    "    # fig.savefig('wh.png', dpi=200)\n",
    "\n",
    "    # Evolve\n",
    "    npr = np.random\n",
    "    f, sh, mp, s = anchor_fitness(k), k.shape, 0.9, 0.1  # fitness, generations, mutation prob, sigma\n",
    "    pbar = tqdm(range(gen), desc='Evolving anchors with Genetic Algorithm')  # progress bar\n",
    "    for _ in pbar:\n",
    "        v = np.ones(sh)\n",
    "        while (v == 1).all():  # mutate until a change occurs (prevent duplicates)\n",
    "            v = ((npr.random(sh) < mp) * npr.random() * npr.randn(*sh) * s + 1).clip(0.3, 3.0)\n",
    "        kg = (k.copy() * v).clip(min=2.0)\n",
    "        fg = anchor_fitness(kg)\n",
    "        if fg > f:\n",
    "            f, k = fg, kg.copy()\n",
    "            pbar.desc = 'Evolving anchors with Genetic Algorithm: fitness = %.4f' % f\n",
    "            if verbose:\n",
    "                print_results(k)\n",
    "\n",
    "    return print_results(k)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8966346153846154, 0.7836538461538461)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "10 / 416\n",
    "\n",
    "373 / 416, 326 / 416"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def IoU(box1, box2) :\n",
    "    # box = [x,y,w,h]\n",
    "\n",
    "    \n",
    "    box1_w = box1[..., 2:3]\n",
    "    box1_h = box1[..., 3:4]\n",
    "    box2_w = box2[..., 2:3]\n",
    "    box2_h = box2[..., 3:4]\n",
    "\n",
    "    box1_area = box1_w * box1_h\n",
    "    box2_area = box2_w * box2_h\n",
    "\n",
    "    box1_xmin = box1[..., 0:1] - box1_w / 2\n",
    "    box1_ymin = box1[..., 1:2] - box1_h / 2\n",
    "    box1_xmax = box1[..., 0:1] + box1_w / 2\n",
    "    box1_ymax = box1[..., 1:2] + box1_w / 2\n",
    "\n",
    "    box2_xmin = box2[..., 0:1] - box2_w / 2\n",
    "    box2_ymin = box2[..., 1:2] - box2_h / 2\n",
    "    box2_xmax = box2[..., 0:1] + box2_w / 2\n",
    "    box2_ymax = box2[..., 1:2] + box2_w / 2\n",
    "    \n",
    "    box1_topleft = torch.cat([box1_xmin, box1_ymin], axis = -1)\n",
    "    box2_topleft = torch.cat([box2_xmin, box2_ymin], axis = -1)\n",
    "\n",
    "    box1_bottomright = torch.cat([box1_xmax, box1_ymax], axis = -1)\n",
    "    box2_bottomright = torch.cat([box2_xmax, box2_ymax], axis = -1)\n",
    "\n",
    "    top_left = torch.max(box1_topleft, box2_topleft)\n",
    "    bottom_right = torch.min(box1_bottomright, box2_bottomright)\n",
    "\n",
    "\n",
    "\n",
    "    area_inter = torch.prod(\n",
    "        torch.clip(bottom_right - top_left, min = 0 , max = None), -1).unsqueeze(-1)\n",
    "    \n",
    "\n",
    "\n",
    "    return area_inter / (box1_area + box2_area - area_inter + 1e-9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorized_IoU(boxes_a, boxes_b) :\n",
    "    def box_area(box) :\n",
    "        return box[2] * box[3]\n",
    "\n",
    "    area_a = box_area(boxes_a.T)\n",
    "    area_b = box_area(boxes_b.T)\n",
    "    \n",
    "    boxes_a_xmin = boxes_a[..., 0:1] - boxes_a[..., 2:3] / 2\n",
    "    boxes_a_xmax = boxes_a[..., 0:1] + boxes_a[..., 2:3] / 2\n",
    "    boxes_a_ymin = boxes_a[..., 1:2] - boxes_a[..., 3:4] / 2\n",
    "    boxes_a_ymax = boxes_a[..., 1:2] + boxes_a[..., 3:4] / 2\n",
    "\n",
    "    boxes_b_xmin = boxes_b[..., 0:1] - boxes_b[..., 2:3] / 2\n",
    "    boxes_b_xmax = boxes_b[..., 0:1] + boxes_b[..., 2:3] / 2\n",
    "    boxes_b_ymin = boxes_b[..., 1:2] - boxes_b[..., 3:4] / 2\n",
    "    boxes_b_ymax = boxes_b[..., 1:2] + boxes_b[..., 3:4] / 2\n",
    "\n",
    "    boxes_a_topleft = np.concatenate([boxes_a_xmin, boxes_a_ymin], axis = -1)\n",
    "    boxes_a_bottomright = np.concatenate([boxes_a_xmax, boxes_a_ymax], axis = -1)\n",
    "\n",
    "    boxes_b_topleft = np.concatenate([boxes_b_xmin, boxes_b_ymin], axis = -1)\n",
    "    boxes_b_bottomright = np.concatenate([boxes_b_xmax, boxes_b_ymax], axis = -1)\n",
    "    \n",
    "    top_left = np.maximum(boxes_a_topleft[..., None, :], boxes_b_topleft )\n",
    "    bottom_right = np.minimum(boxes_a_bottomright[..., None, :], boxes_b_bottomright)\n",
    "\n",
    "    area_inter = np.prod(\n",
    "        np.clip(bottom_right - top_left, a_min = 0, a_max = None), -1\n",
    "    )\n",
    "\n",
    "    return area_inter / (area_a[..., None] + area_b - area_inter )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nms(predictions, confidence_threshold: float , iou_threshold: float) :\n",
    "    '''\n",
    "    vectorize nms\n",
    "    reference : https://blog.roboflow.com/how-to-code-non-maximum-suppression-nms-in-plain-numpy/\n",
    "    '''\n",
    "    predictions = np.array(predictions)\n",
    "    rows, columns = predictions.shape\n",
    "    assert columns == 6, 'bbox should contain [confidence_score, x_center, y_center, w, h, pred_class]'\n",
    "    \n",
    "    sort_index = np.flip(predictions[:,0].argsort())\n",
    "    predictions = predictions[sort_index]\n",
    "\n",
    "    boxes = predictions[:, 1:5]\n",
    "    categories = predictions[:, -1]\n",
    "    ious = vectorized_IoU(torch.tensor(boxes), torch.tensor(boxes)).detach().cpu().numpy()\n",
    "    ious = ious - np.eye(rows)\n",
    "    keep = predictions[:, 0] > confidence_threshold # np.ones(rows, dtype = bool)\n",
    "\n",
    "    for index, (iou, category) in enumerate(zip(ious, categories)) :\n",
    "        if not keep[index] :\n",
    "            continue\n",
    "    \n",
    "        condition = (iou > iou_threshold) & (categories == category)\n",
    "        keep = keep & ~condition\n",
    "\n",
    "    return predictions[keep[sort_index.argsort()]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.1429, 0.0000],\n",
       "        [0.0000, 1.0000, 0.0000, 0.1111],\n",
       "        [0.1429, 0.0000, 1.0000, 0.0000],\n",
       "        [0.0000, 0.1111, 0.0000, 1.0000]])"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bboxes = torch.tensor([\n",
    "    [0.9, .2, .4, .2, .2, 1], # 0.1, 0.3, 0.1, 0.3\n",
    "    [0.8, .6, .4, .2, .2, 1], # 0.5, 0.3, 0.7, 0.5\n",
    "    [0.7, .3, .3, .2, .2, 1], # 0.2, 0.2, 0.4, 0.4\n",
    "    [0.8, .75, .3, .3,.2, 1]  # 0.6, 0.2, 0.9, 0.4\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "vectorized_IoU(bboxes[...,1:5], bboxes[..., 1:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0.],\n",
       "       [1., 1., 0., 0.],\n",
       "       [1., 1., 1., 0.],\n",
       "       [1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.tril(np.ones((4,4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "def soft_nms(predictions, confidence_threshold, sigma = 0.5) :\n",
    "    '''\n",
    "    vectorize soft_nms\n",
    "    reference : https://blog.roboflow.com/how-to-code-non-maximum-suppression-nms-in-plain-numpy/\n",
    "    weight confidence scores with overlapped boxes\n",
    "    '''\n",
    "    predictions = np.array(predictions)\n",
    "    rows, columns = predictions.shape\n",
    "    assert columns == 6, 'bbox should contain [confidence_score, x_center, y_center, w, h, pred_class]'\n",
    "    \n",
    "    sort_index = np.flip(predictions[:,0].argsort())\n",
    "    predictions = predictions[sort_index]\n",
    "\n",
    "    boxes = predictions[:, 1:5]\n",
    "    categories = predictions[:, -1]\n",
    "    ious = vectorized_IoU(torch.tensor(boxes), torch.tensor(boxes)).detach().cpu().numpy()\n",
    "    ious = ious - np.eye(rows)\n",
    "    \n",
    "\n",
    "    weight = np.exp(- np.tril(ious) ** 2 / sigma)\n",
    "    confidence_weight = np.multiply.reduce(weight, -1)\n",
    "    predictions[..., 0] *= confidence_weight\n",
    "\n",
    "    keep = predictions[..., 0] > confidence_threshold\n",
    "\n",
    "    return predictions[keep]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9      , 0.2      , 0.4      , 0.2      , 0.2      , 1.       ],\n",
       "       [0.8      , 0.75     , 0.3      , 0.3      , 0.2      , 1.       ],\n",
       "       [0.7804888, 0.6      , 0.4      , 0.2      , 0.2      , 1.       ],\n",
       "       [0.6720038, 0.3      , 0.3      , 0.2      , 0.2      , 1.       ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soft_nms(bboxes, confidence_threshold= 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "def soft_nms_pytorch(predictions, sigma=0.5, thresh=0.001, cuda=0):\n",
    "    \"\"\"\n",
    "    from https://github.com/DocF/Soft-NMS/blob/master/softnms_pytorch.py\n",
    "    Build a pytorch implement of Soft NMS algorithm.\n",
    "    # Augments\n",
    "        predictions:        boxes coordinate tensor (format:[confidence_score, x_center, y_center, w, h, category])\n",
    "        sigma:       variance of Gaussian function\n",
    "        thresh:      score thresh\n",
    "        cuda:        CUDA flag\n",
    "    # Return\n",
    "        the index of the selected boxes\n",
    "    \"\"\"\n",
    "\n",
    "    # Indexes concatenate boxes with the last column\n",
    "    N = predictions.shape[0]\n",
    "    if cuda:\n",
    "        indexes = torch.arange(0, N, dtype=torch.float).cuda().view(N, 1)\n",
    "    else:\n",
    "        indexes = torch.arange(0, N, dtype=torch.float).view(N, 1)\n",
    "    predictions = torch.cat((predictions, indexes), dim=1)\n",
    "\n",
    "    # The order of boxes coordinate is [y1,x1,y2,x2]\n",
    "    y1 = predictions[..., 1:2] - predictions[..., 3:4] / 2\n",
    "    x1 = predictions[..., 0:1] - predictions[..., 2:3] / 2\n",
    "    y2 = predictions[..., 1:2] + predictions[..., 3:4] / 2\n",
    "    x2 = predictions[..., 0:1] + predictions[..., 2:3] / 2\n",
    "\n",
    "    x1y1x2y2 = torch.cat([x1,y1,x2,y2], axis = -1)\n",
    "    \n",
    "    scores = predictions[..., 0]\n",
    "    areas = (x2 - x1 + 1) * (y2 - y1 + 1)\n",
    "\n",
    "    for i in range(N):\n",
    "        # intermediate parameters for later parameters exchange\n",
    "        tscore = scores[i].clone()\n",
    "        pos = i + 1\n",
    "\n",
    "        if i != N - 1:\n",
    "            maxscore, maxpos = torch.max(scores[pos:], dim=0)\n",
    "            if tscore < maxscore:\n",
    "                predictions[i], predictions[maxpos.item() + i + 1] = predictions[maxpos.item() + i + 1].clone(), predictions[i].clone()\n",
    "                scores[i], scores[maxpos.item() + i + 1] = scores[maxpos.item() + i + 1].clone(), scores[i].clone()\n",
    "                areas[i], areas[maxpos + i + 1] = areas[maxpos + i + 1].clone(), areas[i].clone()\n",
    "\n",
    "        # IoU calculate\n",
    "        yy1 = np.maximum(x1y1x2y2[i, 1].to(\"cpu\").numpy(), x1y1x2y2[pos:, 1].to(\"cpu\").numpy())\n",
    "        xx1 = np.maximum(x1y1x2y2[i, 0].to(\"cpu\").numpy(), x1y1x2y2[pos:, 0].to(\"cpu\").numpy())\n",
    "        yy2 = np.minimum(x1y1x2y2[i, 3].to(\"cpu\").numpy(), x1y1x2y2[pos:, 3].to(\"cpu\").numpy())\n",
    "        xx2 = np.minimum(x1y1x2y2[i, 2].to(\"cpu\").numpy(), x1y1x2y2[pos:, 2].to(\"cpu\").numpy())\n",
    "        \n",
    "        w = np.maximum(0.0, xx2 - xx1 + 1)\n",
    "        h = np.maximum(0.0, yy2 - yy1 + 1)\n",
    "        inter = torch.tensor(w * h).cuda() if cuda else torch.tensor(w * h)\n",
    "        ovr = torch.div(inter, (areas[i] + areas[pos:] - inter))\n",
    "\n",
    "        # Gaussian decay\n",
    "        weight = torch.exp(-(ovr * ovr) / sigma)\n",
    "        scores[pos:] = weight * scores[pos:]\n",
    "\n",
    "    # select the boxes and keep the corresponding indexes\n",
    "    keep = predictions[:, 4][scores > thresh].int()\n",
    "\n",
    "    return keep\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "coco_bboxes = torch.tensor([\n",
    "    [1, .1, .2, .3, .4, 1], # 0.1, 0.2, 0.3, 0.4\n",
    "    [0.5, .5, .3, .7, .5, 1], # 0.5, 0.3, 0.7, 0.5\n",
    "    [0.5, .2, .2, .4, .4, 1], # 0.2, 0.2, 0.4, 0.4\n",
    "    [0.7, .6, .2, .9,.4, 1]  # 0.6, 0.2, 0.9, 0.4\n",
    "])\n",
    "\n",
    "bboxes = torch.tensor([\n",
    "    [1, .2, .4, .2, .2, 1], # 0.1, 0.3, 0.1, 0.3\n",
    "    [0.5, .6, .4, .2, .2, 1], # 0.5, 0.3, 0.7, 0.5\n",
    "    [0.5, .3, .3, .2, .2, 1], # 0.2, 0.2, 0.4, 0.4\n",
    "    [0.7, .75, .3, .3,.2, 1]  # 0.6, 0.2, 0.9, 0.4\n",
    "])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "expand(torch.FloatTensor{[3, 3]}, size=[3]): the number of sizes provided (1) must be greater or equal to the number of dimensions in the tensor (2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[273], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m soft_nms_pytorch(bboxes)\n",
      "Cell \u001b[1;32mIn[271], line 58\u001b[0m, in \u001b[0;36msoft_nms_pytorch\u001b[1;34m(predictions, sigma, thresh, cuda)\u001b[0m\n\u001b[0;32m     56\u001b[0m     \u001b[39m# Gaussian decay\u001b[39;00m\n\u001b[0;32m     57\u001b[0m     weight \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mexp(\u001b[39m-\u001b[39m(ovr \u001b[39m*\u001b[39m ovr) \u001b[39m/\u001b[39m sigma)\n\u001b[1;32m---> 58\u001b[0m     scores[pos:] \u001b[39m=\u001b[39m weight \u001b[39m*\u001b[39m scores[pos:]\n\u001b[0;32m     60\u001b[0m \u001b[39m# select the boxes and keep the corresponding indexes\u001b[39;00m\n\u001b[0;32m     61\u001b[0m keep \u001b[39m=\u001b[39m predictions[:, \u001b[39m4\u001b[39m][scores \u001b[39m>\u001b[39m thresh]\u001b[39m.\u001b[39mint()\n",
      "\u001b[1;31mRuntimeError\u001b[0m: expand(torch.FloatTensor{[3, 3]}, size=[3]): the number of sizes provided (1) must be greater or equal to the number of dimensions in the tensor (2)"
     ]
    }
   ],
   "source": [
    "soft_nms_pytorch(bboxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.9000, 0.8000, 0.2762, 0.0970, 0.0517])"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boxes = torch.tensor([[200, 200, 400, 400],\n",
    "                          [220, 220, 420, 420],\n",
    "                          [200, 240, 400, 440],\n",
    "                          [240, 200, 440, 400],\n",
    "                          [1, 1, 2, 2]])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "boxscores = torch.tensor([0.8, 0.7, 0.6, 0.5, 0.9], dtype=torch.float)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "keep, scores = soft_nms_pytorch(boxes, boxscores, thresh = 0.81)\n",
    "\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.  , 0.2 , 0.4 , 0.2 , 0.2 , 1.  ],\n",
       "       [0.7 , 0.75, 0.3 , 0.3 , 0.2 , 1.  ]], dtype=float32)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soft_nms(bboxes, confidence_threshold = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "def box_iou_batch(boxes_a, boxes_b):\n",
    "    boxes_a = np.array(boxes_a)\n",
    "    boxes_b = np.array(boxes_b)\n",
    "    def box_area(box):\n",
    "        return (box[2] - box[0]) * (box[3] - box[1])\n",
    "\n",
    "    area_a = box_area(boxes_a.T)\n",
    "    area_b = box_area(boxes_b.T)\n",
    "\n",
    "    top_left = np.maximum(boxes_a[..., :2], boxes_b[..., :2])\n",
    "    bottom_right = np.minimum(boxes_a[..., None, 2:], boxes_b[..., 2:])\n",
    "\n",
    "    \n",
    "\n",
    "    area_inter = np.prod(\n",
    "    \tnp.clip(bottom_right - top_left, a_min=0, a_max=None), axis = -1)\n",
    "        \n",
    "    return area_inter / (area_a[..., None] + area_b - area_inter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.00000000e+00, 6.80672269e-01, 6.66666667e-01, 6.66666667e-01,\n",
       "        2.50000000e-05],\n",
       "       [1.00000000e+00, 1.00000000e+00, 8.18181818e-01, 8.18181818e-01,\n",
       "        2.50000000e-05],\n",
       "       [1.00000000e+00, 8.18181818e-01, 1.00000000e+00, 6.66666667e-01,\n",
       "        2.50000000e-05],\n",
       "       [1.00000000e+00, 8.18181818e-01, 6.66666667e-01, 1.00000000e+00,\n",
       "        2.50000000e-05],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        1.00000000e+00]])"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "box_iou_batch(boxes,boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxes_confidence = torch.tensor([[0.8, 200, 200, 400, 400],\n",
    "                                    [0.7, 220, 220, 420, 420],\n",
    "                                    [0.6, 200, 240, 400, 440],\n",
    "                                    [0.5, 240, 200, 440, 400],\n",
    "                                    [0.6, 1, 1, 2, 2]], dtype = torch.float32)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = 0.5\n",
    "\n",
    "boxes_confidence = np.array(boxes_confidence)\n",
    "boxscores = boxes_confidence[:,0]\n",
    "sort_index = np.flip(boxscores.argsort())\n",
    "boxes_confidence = boxes_confidence[sort_index]\n",
    "boxes = boxes_confidence[..., 1:5]\n",
    "\n",
    "ious = box_iou_batch(boxes,boxes)\n",
    "ious = ious - np.eye(5)\n",
    "weight = np.exp(- np.tril(ious) ** 2 / sigma)\n",
    "confidence_weight = np.multiply.reduce(weight, -1)\n",
    "boxscores *= confidence_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.9       , 0.8       , 0.0947347 , 0.02128679, 0.00729272],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boxscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.9000, 0.8000, 0.2762, 0.0970, 0.0517])"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
