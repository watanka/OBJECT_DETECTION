{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6900)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sigmoid(torch.tensor(0.8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([], size=(3, 0))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([  [], [[1,2],[3,4]] , [[1,2]]         ] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "numgrid = 7\n",
    "numbox = 5\n",
    "num_classes = 13\n",
    "\n",
    "labelgrid = torch.randn((batch_size, numgrid, numgrid, numbox, 5 + num_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 7, 7, 5])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros_like(labelgrid[..., 0]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5000, 0.5000, 0.5000, 0.5000]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sigmoid(torch.tensor([[0,0,0,0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2x3x3x4=\n",
    "seq = torch.arange(2*3*3*5*4).contiguous()\n",
    "\n",
    "grid = seq.reshape(2,3,3,5,4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[[0, 0, 0, 0],\n",
       "           [0, 0, 0, 0],\n",
       "           [0, 0, 0, 0]],\n",
       "\n",
       "          [[0, 0, 0, 0],\n",
       "           [0, 0, 0, 0],\n",
       "           [0, 0, 0, 0]],\n",
       "\n",
       "          [[0, 0, 0, 0],\n",
       "           [0, 0, 0, 0],\n",
       "           [0, 0, 0, 0]],\n",
       "\n",
       "          ...,\n",
       "\n",
       "          [[0, 0, 0, 0],\n",
       "           [0, 0, 0, 0],\n",
       "           [0, 0, 0, 0]],\n",
       "\n",
       "          [[0, 0, 0, 0],\n",
       "           [0, 0, 0, 0],\n",
       "           [0, 0, 0, 0]],\n",
       "\n",
       "          [[0, 0, 0, 0],\n",
       "           [0, 0, 0, 0],\n",
       "           [0, 0, 0, 0]]],\n",
       "\n",
       "\n",
       "         [[[0, 0, 0, 0],\n",
       "           [0, 0, 0, 0],\n",
       "           [0, 0, 0, 0]],\n",
       "\n",
       "          [[0, 0, 0, 0],\n",
       "           [0, 0, 0, 0],\n",
       "           [0, 0, 0, 0]],\n",
       "\n",
       "          [[0, 0, 0, 0],\n",
       "           [0, 0, 0, 0],\n",
       "           [0, 0, 0, 0]],\n",
       "\n",
       "          ...,\n",
       "\n",
       "          [[0, 0, 0, 0],\n",
       "           [0, 0, 0, 0],\n",
       "           [0, 0, 0, 0]],\n",
       "\n",
       "          [[0, 0, 0, 0],\n",
       "           [0, 0, 0, 0],\n",
       "           [0, 0, 0, 0]],\n",
       "\n",
       "          [[0, 0, 0, 0],\n",
       "           [0, 0, 0, 0],\n",
       "           [0, 0, 0, 0]]],\n",
       "\n",
       "\n",
       "         [[[0, 0, 0, 0],\n",
       "           [0, 0, 0, 0],\n",
       "           [0, 0, 0, 0]],\n",
       "\n",
       "          [[0, 0, 0, 0],\n",
       "           [0, 0, 0, 0],\n",
       "           [0, 0, 0, 0]],\n",
       "\n",
       "          [[0, 0, 0, 0],\n",
       "           [0, 0, 0, 0],\n",
       "           [0, 0, 0, 0]],\n",
       "\n",
       "          ...,\n",
       "\n",
       "          [[0, 0, 0, 0],\n",
       "           [0, 0, 0, 0],\n",
       "           [0, 0, 0, 0]],\n",
       "\n",
       "          [[0, 0, 0, 0],\n",
       "           [0, 0, 0, 0],\n",
       "           [0, 0, 0, 0]],\n",
       "\n",
       "          [[0, 0, 0, 0],\n",
       "           [0, 0, 0, 0],\n",
       "           [0, 0, 0, 0]]],\n",
       "\n",
       "\n",
       "         [[[0, 0, 0, 0],\n",
       "           [0, 0, 0, 0],\n",
       "           [0, 0, 0, 0]],\n",
       "\n",
       "          [[0, 0, 0, 0],\n",
       "           [0, 0, 0, 0],\n",
       "           [0, 0, 0, 0]],\n",
       "\n",
       "          [[0, 0, 0, 0],\n",
       "           [0, 0, 0, 0],\n",
       "           [0, 0, 0, 0]],\n",
       "\n",
       "          ...,\n",
       "\n",
       "          [[0, 0, 0, 0],\n",
       "           [0, 0, 0, 0],\n",
       "           [0, 0, 0, 0]],\n",
       "\n",
       "          [[0, 0, 0, 0],\n",
       "           [0, 0, 0, 0],\n",
       "           [0, 0, 0, 0]],\n",
       "\n",
       "          [[0, 0, 0, 0],\n",
       "           [0, 0, 0, 0],\n",
       "           [0, 0, 0, 0]]],\n",
       "\n",
       "\n",
       "         [[[0, 0, 0, 0],\n",
       "           [0, 0, 0, 0],\n",
       "           [0, 0, 0, 0]],\n",
       "\n",
       "          [[0, 0, 0, 0],\n",
       "           [0, 0, 0, 0],\n",
       "           [0, 0, 0, 0]],\n",
       "\n",
       "          [[0, 0, 0, 0],\n",
       "           [0, 0, 0, 0],\n",
       "           [0, 0, 0, 0]],\n",
       "\n",
       "          ...,\n",
       "\n",
       "          [[0, 0, 0, 0],\n",
       "           [0, 0, 0, 0],\n",
       "           [0, 0, 0, 0]],\n",
       "\n",
       "          [[0, 0, 0, 0],\n",
       "           [0, 0, 0, 0],\n",
       "           [0, 0, 0, 0]],\n",
       "\n",
       "          [[0, 0, 0, 0],\n",
       "           [0, 0, 0, 0],\n",
       "           [0, 0, 0, 0]]],\n",
       "\n",
       "\n",
       "         [[[0, 0, 0, 0],\n",
       "           [0, 0, 0, 0],\n",
       "           [0, 0, 0, 0]],\n",
       "\n",
       "          [[0, 0, 0, 0],\n",
       "           [0, 0, 0, 0],\n",
       "           [0, 0, 0, 0]],\n",
       "\n",
       "          [[0, 0, 0, 0],\n",
       "           [0, 0, 0, 0],\n",
       "           [0, 0, 0, 0]],\n",
       "\n",
       "          ...,\n",
       "\n",
       "          [[0, 0, 0, 0],\n",
       "           [0, 0, 0, 0],\n",
       "           [0, 0, 0, 0]],\n",
       "\n",
       "          [[0, 0, 0, 0],\n",
       "           [0, 0, 0, 0],\n",
       "           [0, 0, 0, 0]],\n",
       "\n",
       "          [[0, 0, 0, 0],\n",
       "           [0, 0, 0, 0],\n",
       "           [0, 0, 0, 0]]]],\n",
       "\n",
       "\n",
       "\n",
       "        [[[[0, 0, 0, 0],\n",
       "           [0, 0, 0, 0],\n",
       "           [0, 0, 0, 0]],\n",
       "\n",
       "          [[0, 0, 0, 0],\n",
       "           [0, 0, 0, 0],\n",
       "           [0, 0, 0, 0]],\n",
       "\n",
       "          [[0, 0, 0, 0],\n",
       "           [0, 0, 0, 0],\n",
       "           [0, 0, 0, 0]],\n",
       "\n",
       "          ...,\n",
       "\n",
       "          [[0, 0, 0, 0],\n",
       "           [0, 0, 0, 0],\n",
       "           [0, 0, 0, 0]],\n",
       "\n",
       "          [[0, 0, 0, 0],\n",
       "           [0, 0, 0, 0],\n",
       "           [0, 0, 0, 0]],\n",
       "\n",
       "          [[0, 0, 0, 0],\n",
       "           [0, 0, 0, 0],\n",
       "           [0, 0, 0, 0]]],\n",
       "\n",
       "\n",
       "         [[[0, 0, 0, 0],\n",
       "           [0, 0, 0, 0],\n",
       "           [0, 0, 0, 0]],\n",
       "\n",
       "          [[0, 0, 0, 0],\n",
       "           [0, 0, 0, 0],\n",
       "           [0, 0, 0, 0]],\n",
       "\n",
       "          [[0, 0, 0, 0],\n",
       "           [0, 0, 0, 0],\n",
       "           [0, 0, 0, 0]],\n",
       "\n",
       "          ...,\n",
       "\n",
       "          [[0, 0, 0, 0],\n",
       "           [0, 0, 0, 0],\n",
       "           [0, 0, 0, 0]],\n",
       "\n",
       "          [[0, 0, 0, 0],\n",
       "           [0, 0, 0, 0],\n",
       "           [0, 0, 0, 0]],\n",
       "\n",
       "          [[0, 0, 0, 0],\n",
       "           [0, 0, 0, 0],\n",
       "           [0, 0, 0, 0]]],\n",
       "\n",
       "\n",
       "         [[[0, 0, 0, 0],\n",
       "           [0, 0, 0, 0],\n",
       "           [0, 0, 0, 0]],\n",
       "\n",
       "          [[0, 0, 0, 0],\n",
       "           [0, 0, 0, 0],\n",
       "           [0, 0, 0, 0]],\n",
       "\n",
       "          [[0, 0, 0, 0],\n",
       "           [0, 0, 0, 0],\n",
       "           [0, 0, 0, 0]],\n",
       "\n",
       "          ...,\n",
       "\n",
       "          [[0, 0, 0, 0],\n",
       "           [0, 0, 0, 0],\n",
       "           [0, 0, 0, 0]],\n",
       "\n",
       "          [[0, 0, 0, 0],\n",
       "           [0, 0, 0, 0],\n",
       "           [0, 0, 0, 0]],\n",
       "\n",
       "          [[0, 0, 0, 0],\n",
       "           [0, 0, 0, 0],\n",
       "           [0, 0, 0, 0]]],\n",
       "\n",
       "\n",
       "         [[[0, 0, 0, 0],\n",
       "           [0, 0, 0, 0],\n",
       "           [0, 0, 0, 0]],\n",
       "\n",
       "          [[0, 0, 0, 0],\n",
       "           [0, 0, 0, 0],\n",
       "           [0, 0, 0, 0]],\n",
       "\n",
       "          [[0, 0, 0, 0],\n",
       "           [0, 0, 0, 0],\n",
       "           [0, 0, 0, 0]],\n",
       "\n",
       "          ...,\n",
       "\n",
       "          [[0, 0, 0, 0],\n",
       "           [0, 0, 0, 0],\n",
       "           [0, 0, 0, 0]],\n",
       "\n",
       "          [[0, 0, 0, 0],\n",
       "           [0, 0, 0, 0],\n",
       "           [0, 0, 0, 0]],\n",
       "\n",
       "          [[0, 0, 0, 0],\n",
       "           [0, 0, 0, 0],\n",
       "           [0, 0, 0, 0]]],\n",
       "\n",
       "\n",
       "         [[[0, 0, 0, 0],\n",
       "           [0, 0, 0, 0],\n",
       "           [0, 0, 0, 0]],\n",
       "\n",
       "          [[0, 0, 0, 0],\n",
       "           [0, 0, 0, 0],\n",
       "           [0, 0, 0, 0]],\n",
       "\n",
       "          [[0, 0, 0, 0],\n",
       "           [0, 0, 0, 0],\n",
       "           [0, 0, 0, 0]],\n",
       "\n",
       "          ...,\n",
       "\n",
       "          [[0, 0, 0, 0],\n",
       "           [0, 0, 0, 0],\n",
       "           [0, 0, 0, 0]],\n",
       "\n",
       "          [[0, 0, 0, 0],\n",
       "           [0, 0, 0, 0],\n",
       "           [0, 0, 0, 0]],\n",
       "\n",
       "          [[0, 0, 0, 0],\n",
       "           [0, 0, 0, 0],\n",
       "           [0, 0, 0, 0]]],\n",
       "\n",
       "\n",
       "         [[[0, 0, 0, 0],\n",
       "           [0, 0, 0, 0],\n",
       "           [0, 0, 0, 0]],\n",
       "\n",
       "          [[0, 0, 0, 0],\n",
       "           [0, 0, 0, 0],\n",
       "           [0, 0, 0, 0]],\n",
       "\n",
       "          [[0, 0, 0, 0],\n",
       "           [0, 0, 0, 0],\n",
       "           [0, 0, 0, 0]],\n",
       "\n",
       "          ...,\n",
       "\n",
       "          [[0, 0, 0, 0],\n",
       "           [0, 0, 0, 0],\n",
       "           [0, 0, 0, 0]],\n",
       "\n",
       "          [[0, 0, 0, 0],\n",
       "           [0, 0, 0, 0],\n",
       "           [0, 0, 0, 0]],\n",
       "\n",
       "          [[0, 0, 0, 0],\n",
       "           [0, 0, 0, 0],\n",
       "           [0, 0, 0, 0]]]]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_mask = torch.zeros((2,3,3,1), dtype = torch.int64)\n",
    "\n",
    "grid_mask + i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[[  0,   1,   2,   3]],\n",
       "\n",
       "          [[ 20,  21,  22,  23]],\n",
       "\n",
       "          [[ 40,  41,  42,  43]]],\n",
       "\n",
       "\n",
       "         [[[ 60,  61,  62,  63]],\n",
       "\n",
       "          [[ 80,  81,  82,  83]],\n",
       "\n",
       "          [[100, 101, 102, 103]]],\n",
       "\n",
       "\n",
       "         [[[120, 121, 122, 123]],\n",
       "\n",
       "          [[140, 141, 142, 143]],\n",
       "\n",
       "          [[160, 161, 162, 163]]]],\n",
       "\n",
       "\n",
       "\n",
       "        [[[[180, 181, 182, 183]],\n",
       "\n",
       "          [[200, 201, 202, 203]],\n",
       "\n",
       "          [[220, 221, 222, 223]]],\n",
       "\n",
       "\n",
       "         [[[240, 241, 242, 243]],\n",
       "\n",
       "          [[260, 261, 262, 263]],\n",
       "\n",
       "          [[280, 281, 282, 283]]],\n",
       "\n",
       "\n",
       "         [[[300, 301, 302, 303]],\n",
       "\n",
       "          [[320, 321, 322, 323]],\n",
       "\n",
       "          [[340, 341, 342, 343]]]]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.gather(grid, -2, grid_mask.unsqueeze(-1).repeat(1,1,1,1,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[  0,   1,   2,   3],\n",
       "          [ 20,  21,  22,  23],\n",
       "          [ 40,  41,  42,  43]],\n",
       "\n",
       "         [[ 60,  61,  62,  63],\n",
       "          [ 80,  81,  82,  83],\n",
       "          [100, 101, 102, 103]],\n",
       "\n",
       "         [[120, 121, 122, 123],\n",
       "          [140, 141, 142, 143],\n",
       "          [160, 161, 162, 163]]],\n",
       "\n",
       "\n",
       "        [[[180, 181, 182, 183],\n",
       "          [200, 201, 202, 203],\n",
       "          [220, 221, 222, 223]],\n",
       "\n",
       "         [[240, 241, 242, 243],\n",
       "          [260, 261, 262, 263],\n",
       "          [280, 281, 282, 283]],\n",
       "\n",
       "         [[300, 301, 302, 303],\n",
       "          [320, 321, 322, 323],\n",
       "          [340, 341, 342, 343]]]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid[..., 0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "numgrid = 7\n",
    "\n",
    "x = torch.arange(numgrid)\n",
    "y = torch.arange(numgrid)\n",
    "\n",
    "grid_y, grid_x = torch.meshgrid(x,y, indexing = 'ij')\n",
    "grid_x = grid_x.expand(8, -1,-1)#.unsqueeze(-1)\n",
    "grid_y = grid_y.expand(8, -1,-1)#.unsqueeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (8) must match the size of tensor b (7) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[147], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m grid_x \u001b[39m*\u001b[39;49m torch\u001b[39m.\u001b[39;49mrandn(\u001b[39m8\u001b[39;49m,\u001b[39m7\u001b[39;49m,\u001b[39m7\u001b[39;49m,\u001b[39m1\u001b[39;49m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The size of tensor a (8) must match the size of tensor b (7) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "grid_x * torch.randn(8,7,7,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = labelgrid[..., 0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = torch.nn.MSELoss()\n",
    "inp = torch.randn((16,13,13, 1))\n",
    "target = torch.randn((16,13,13, 1))\n",
    "output = loss(inp, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.9788)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[15, 25],\n",
       "        [35, 45]])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ls = torch.tensor([[10, 15],[20, 25],[30, 35],[40, 45],[50, 55]])\n",
    "h = ls[:,0]\n",
    "w = ls[:,1]\n",
    "\n",
    "\n",
    "value = torch.tensor([[0,1],\n",
    "                      [2,3]])\n",
    "\n",
    "torch.take(w, value)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = torch.arange(5).repeat(1,5).reshape(5,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3.1623, 3.8730, 4.4721, 5.0000, 5.4772],\n",
       "        [3.1623, 3.8730, 4.4721, 5.0000, 5.4772],\n",
       "        [3.1623, 3.8730, 4.4721, 5.0000, 5.4772],\n",
       "        [3.1623, 3.8730, 4.4721, 5.0000, 5.4772],\n",
       "        [3.1623, 3.8730, 4.4721, 5.0000, 5.4772]])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sqrt(torch.take(ls, indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (5) must match the size of tensor b (7) at non-singleton dimension 3",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[109], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m (torch\u001b[39m.\u001b[39;49mzeros((\u001b[39m8\u001b[39;49m,\u001b[39m7\u001b[39;49m,\u001b[39m7\u001b[39;49m,\u001b[39m5\u001b[39;49m,\u001b[39m1\u001b[39;49m)) \u001b[39m*\u001b[39;49m torch\u001b[39m.\u001b[39;49mrandn((\u001b[39m8\u001b[39;49m,\u001b[39m7\u001b[39;49m,\u001b[39m7\u001b[39;49m,\u001b[39m5\u001b[39;49m)))\u001b[39m.\u001b[39mshape\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The size of tensor a (5) must match the size of tensor b (7) at non-singleton dimension 3"
     ]
    }
   ],
   "source": [
    "(torch.zeros((8,7,7,5,1)) * torch.randn((8,7,7,5))).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "\n",
    "model_paths = {\n",
    "    'darknet19': 'https://s3.ap-northeast-2.amazonaws.com/deepbaksuvision/darknet19-deepBakSu-e1b3ec1e.pth'\n",
    "}\n",
    "\n",
    "class GlobalAvgPool2d(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GlobalAvgPool2d, self).__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        N = x.data.size(0)\n",
    "        C = x.data.size(1)\n",
    "        H = x.data.size(2)\n",
    "        W = x.data.size(3)\n",
    "        x = F.avg_pool2d(x, (H, W))\n",
    "        x = x.view(N, C)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Darknet19(nn.Module):\n",
    "    def __init__(self, pretrained=True):\n",
    "        super(Darknet19, self).__init__()\n",
    "\n",
    "        self.features = nn.Sequential(OrderedDict([\n",
    "        ('layer1', nn.Sequential(OrderedDict([\n",
    "            ('conv1_1', nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1, bias=False)),\n",
    "            ('bn1_1', nn.BatchNorm2d(32)),\n",
    "            ('leaky1_1', nn.LeakyReLU(0.1, inplace=True)),\n",
    "            ('maxpool1', nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        ]))),\n",
    "        ('layer2', nn.Sequential(OrderedDict([\n",
    "            ('conv2_1', nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1, bias=False)),\n",
    "            ('bn2_1', nn.BatchNorm2d(64)),\n",
    "            ('leaky2_1', nn.LeakyReLU(0.1, inplace=True)),\n",
    "            ('maxpool2', nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        ]))),\n",
    "        ('layer3', nn.Sequential(OrderedDict([\n",
    "            ('conv3_1', nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1, bias=False)),\n",
    "            ('bn3_1', nn.BatchNorm2d(128)),\n",
    "            ('leaky3_1', nn.LeakyReLU(0.1, inplace=True)),\n",
    "            ('conv3_2', nn.Conv2d(128, 64, kernel_size=1, stride=1, padding=0, bias=False)),\n",
    "            ('bn3_2', nn.BatchNorm2d(64)),\n",
    "            ('leaky3_2', nn.LeakyReLU(0.1, inplace=True)),\n",
    "            ('conv3_3', nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1, bias=False)),\n",
    "            ('bn3_3', nn.BatchNorm2d(128)),\n",
    "            ('leaky3_3', nn.LeakyReLU(0.1, inplace=True)),\n",
    "            ('maxpool3', nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        ]))),\n",
    "        ('layer4', nn.Sequential(OrderedDict([\n",
    "            ('conv4_1', nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1, bias=False)),\n",
    "            ('bn4_1', nn.BatchNorm2d(256)),\n",
    "            ('leaky4_1', nn.LeakyReLU(0.1, inplace=True)),\n",
    "            ('conv4_2', nn.Conv2d(256, 128, kernel_size=1, stride=1, padding=0, bias=False)),\n",
    "            ('bn4_2', nn.BatchNorm2d(128)),\n",
    "            ('leaky4_2', nn.LeakyReLU(0.1, inplace=True)),\n",
    "            ('conv4_3', nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1, bias=False)),\n",
    "            ('bn4_3', nn.BatchNorm2d(256)),\n",
    "            ('leaky4_3', nn.LeakyReLU(0.1, inplace=True)),\n",
    "            ('maxpool4', nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        ]))),\n",
    "        ('layer5', nn.Sequential(OrderedDict([\n",
    "            ('conv5_1', nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1, bias=False)),\n",
    "            ('bn5_1', nn.BatchNorm2d(512)),\n",
    "            ('leaky5_1', nn.LeakyReLU(0.1, inplace=True)),\n",
    "            ('conv5_2', nn.Conv2d(512, 256, kernel_size=1, stride=1, padding=0, bias=False)),\n",
    "            ('bn5_2', nn.BatchNorm2d(256)),\n",
    "            ('leaky5_2', nn.LeakyReLU(0.1, inplace=True)),\n",
    "            ('conv5_3', nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1, bias=False)),\n",
    "            ('bn5_3', nn.BatchNorm2d(512)),\n",
    "            ('leaky5_3', nn.LeakyReLU(0.1, inplace=True)),\n",
    "            ('conv5_4', nn.Conv2d(512, 256, kernel_size=1, stride=1, padding=1, bias=False)),\n",
    "            ('bn5_4', nn.BatchNorm2d(256)),\n",
    "            ('leaky5_4', nn.LeakyReLU(0.1, inplace=True)),\n",
    "            ('conv5_5', nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1, bias=False)),\n",
    "            ('bn5_5', nn.BatchNorm2d(512)),\n",
    "            ('leaky5_5', nn.LeakyReLU(0.1, inplace=True)),\n",
    "            ('maxpool5', nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        ]))),\n",
    "        ('layer6', nn.Sequential(OrderedDict([\n",
    "            ('conv6_1', nn.Conv2d(512, 1024, kernel_size=3, stride=1, padding=1, bias=False)),\n",
    "            ('bn6_1', nn.BatchNorm2d(1024)),\n",
    "            ('leaky6_1', nn.LeakyReLU(0.1, inplace=True)),\n",
    "            ('conv6_2', nn.Conv2d(1024, 512, kernel_size=1, stride=1, padding=0, bias=False)),\n",
    "            ('bn6_2', nn.BatchNorm2d(512)),\n",
    "            ('leaky6_2', nn.LeakyReLU(0.1, inplace=True)),\n",
    "            ('conv6_3', nn.Conv2d(512, 1024, kernel_size=3, stride=1, padding=1, bias=False)),\n",
    "            ('bn6_3', nn.BatchNorm2d(1024)),\n",
    "            ('leaky6_3', nn.LeakyReLU(0.1, inplace=True)),\n",
    "            ('conv6_4', nn.Conv2d(1024, 512, kernel_size=1, stride=1, padding=1, bias=False)),\n",
    "            ('bn6_4', nn.BatchNorm2d(512)),\n",
    "            ('leaky6_4', nn.LeakyReLU(0.1, inplace=True)),\n",
    "            ('conv6_5', nn.Conv2d(512, 1024, kernel_size=3, stride=1, padding=1, bias=False)),\n",
    "            ('bn6_5', nn.BatchNorm2d(1024)),\n",
    "            ('leaky6_5', nn.LeakyReLU(0.1, inplace=True))\n",
    "        ])))\n",
    "        ]))\n",
    "\n",
    "        self.classifier = nn.Sequential(OrderedDict([\n",
    "        ('conv7_1', nn.Conv2d(1024, 1000, kernel_size=(1, 1), stride=(1, 1))),\n",
    "        ('globalavgpool', GlobalAvgPool2d()),\n",
    "        ('softmax', nn.Softmax(dim=1))\n",
    "        ]))\n",
    "\n",
    "        # if pretrained:\n",
    "        #     self.load_state_dict(model_zoo.load_url(model_paths['darknet19'],  progress=True))\n",
    "        #     print('Model is loaded')\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.features :\n",
    "            print(layer)\n",
    "            print('.')\n",
    "        # out = self.features(x)\n",
    "        # out = self.classifier(out)\n",
    "        # return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Darknet19()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (conv1_1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn1_1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky1_1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "  (maxpool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      ")\n",
      ".\n",
      "Sequential(\n",
      "  (conv2_1): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2_1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky2_1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "  (maxpool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      ")\n",
      ".\n",
      "Sequential(\n",
      "  (conv3_1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn3_1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky3_1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "  (conv3_2): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn3_2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky3_2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "  (conv3_3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn3_3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky3_3): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "  (maxpool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      ")\n",
      ".\n",
      "Sequential(\n",
      "  (conv4_1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn4_1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky4_1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "  (conv4_2): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn4_2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky4_2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "  (conv4_3): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn4_3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky4_3): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "  (maxpool4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      ")\n",
      ".\n",
      "Sequential(\n",
      "  (conv5_1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn5_1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky5_1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "  (conv5_2): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn5_2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky5_2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "  (conv5_3): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn5_3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky5_3): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "  (conv5_4): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn5_4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky5_4): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "  (conv5_5): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn5_5): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky5_5): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "  (maxpool5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      ")\n",
      ".\n",
      "Sequential(\n",
      "  (conv6_1): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn6_1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky6_1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "  (conv6_2): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn6_2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky6_2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "  (conv6_3): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn6_3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky6_3): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "  (conv6_4): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn6_4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky6_4): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "  (conv6_5): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn6_5): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky6_5): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      ")\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "model(torch.rand(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 7, 7, 5])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros_like(torch.randn((8,7,7,5,24))[...,0]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
