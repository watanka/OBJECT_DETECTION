{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2 ways to improve the performance\n",
    "# yolov2 : changes in model configurations\n",
    "# yolo9000 : changes in model training method. joint training of classification and object detection.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from global_utils import IoU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anchor Boxes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### k-mean clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## https://towardsdatascience.com/create-your-own-k-means-clustering-algorithm-in-python-d7d4c9077670\n",
    "\n",
    "def KmeanClustering(bboxes, max_iters, k = 5) :\n",
    "    '''\n",
    "    read out whole bounding boxes from train datasets, and perform k mean clusterings\n",
    "    bboxes = (x_center, y_center, w, h, c). Here ratios are respect to the image size, NOT grid cell.\n",
    "    max_iters : number of maximum iterations\n",
    "    k : number of clusters\n",
    "    '''\n",
    "\n",
    "    w = bboxes[:, 2]\n",
    "    h = bboxes[:, 3]\n",
    "\n",
    "    # initialize the centroid\n",
    "    min_w, max_w = min(w), max(w)\n",
    "    min_h, max_h = min(h), max(h)\n",
    "    # uniformly distribute the k cluster centroids\n",
    "    centroids = [((max_w - min_w) * (i+1), (max_h - min_h) * (i+1)) for i in range(k)]\n",
    "\n",
    "    prev_centroids = None\n",
    "    iteration = 0\n",
    "\n",
    "\n",
    "    while np.not_equal(centroids, prev_centroid).any() or iteration < max_iters :\n",
    "        \n",
    "        sorted_points = [[] for _ in range(k)]\n",
    "\n",
    "        for (_, _, w, h, _) in bboxes :\n",
    "            \n",
    "            # Suppose x_center and y_center are same for centroid and data point here, we just want the ratio of w, h.\n",
    "            x, y = 0.5, 0.5\n",
    "\n",
    "\n",
    "\n",
    "            dist = np.array([IoU(np.array([x,y,w,h]), np.array([x,y,centroid_w, centroid_h]) ) \\\n",
    "                                for (centroid_w, centroid_h) in centroids])\n",
    "\n",
    "            centroid_idx = np.argmax(dist)\n",
    "            sorted_points[centroid_idx].append([w, h])\n",
    "\n",
    "        prev_centroids = centroids\n",
    "        sorted_points = np.array(sorted_points)\n",
    "        centroids = [(np.mean(cluster[:,0]), np.mean(cluster[:,1]) ) for cluster in sorted_points]\n",
    "\n",
    "        # if any new centroids has NaN, then substitute back to previous centroids\n",
    "        centroids[np.isnan(centroids)] = prev_centroids[np.isnan(centroids)]\n",
    "\n",
    "        iteration += 1\n",
    "\n",
    "    return centroids\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samp = np.array([[np.NaN, 0, 0, 0]])\n",
    "prev = np.array([[1, 2, 3, 4]])\n",
    "samp[np.isnan(samp)] = prev[np.isnan(samp)]\n",
    "\n",
    "\n",
    "samp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "reference : https://pyimagesearch.com/2022/05/02/mean-average-precision-map-using-the-coco-evaluator/\n",
    "usage : validation, evaluation. \n",
    "predictions and gts will be handed by reading gtfile directly, since dataloader limits the number of gt bounding box\n",
    "'''\n",
    "\n",
    "\n",
    "from global_utils import IoU\n",
    "\n",
    "## MAP\n",
    "\n",
    "class MeanAveragePrecisionMetrics :\n",
    "    def __init__(self, gts, preds, num_classes, iou_threshold_range, confidence_threshold) :\n",
    "        '''\n",
    "        gts, preds = [[[class, x, y, w, h, c],...], ...] # imgs x bboxes\n",
    "\n",
    "        num_classes : # of classes, make sure the class numbers starts from 0 and increased by 1.\n",
    "        iou_threshold_range : (min_threshold, interval, max_threshold). e.g) IoU(0.6, 0.1, 0.9) = [0.6, 0.7, 0.8, 0.9]\n",
    "        confidence_threshold : predicted bounding boxes are filtered by confidence threshold\n",
    "        '''\n",
    "        self.gts = gts\n",
    "        self.preds = preds\n",
    "        assert len(gts) == len(preds), '# of images should be the same for predictions and ground truths.'\n",
    "        self.num_classes = num_classes \n",
    "        # convert iou_threshold_range into list\n",
    "        min_threshold, interval, max_threshold  = iou_threshold_range\n",
    "        self.iou_threshold_range = np.linspace(min_threshold, max_threshold, num=int((max_threshold - min_threshold)//interval + 1))\n",
    "        \n",
    "        self.confidence_threshold = confidence_threshold\n",
    "        self.iou_table_per_img = {imgidx : None for imgidx in range(len(gts))}\n",
    "\n",
    "        # self.total_iou_table = {clslabel : {iou_threshold : None \\\n",
    "        #                                         for iou_threshold in self.iou_threshold_range} \\\n",
    "        #                                             for clslabel in range(num_classes)}\n",
    "\n",
    "        self.TOTAL_TP = [{iou_threshold : 0 for iou_threshold in self.iou_threshold_range} for _ in range(num_classes)]\n",
    "        self.TOTAL_FP = [{iou_threshold : 0 for iou_threshold in self.iou_threshold_range} for _ in range(num_classes)]\n",
    "        self.TOTAL_FN = [{iou_threshold : 0 for iou_threshold in self.iou_threshold_range} for _ in range(num_classes)]\n",
    "\n",
    "        self.total_statistics = []\n",
    "\n",
    "\n",
    "    def calculate_PR(self, imgidx, pred, gt, iou_threshold) :\n",
    "        '''\n",
    "        calculate precision and recall per classes\n",
    "        Recall = TP / (TP+FN)\n",
    "        Precision = TP / (TP + FP)\n",
    "        1. match preds and gts using IoU\n",
    "        2. matched preds will be TP, and remaining unmatched preds will be FP, and unmatched gt are FN.\n",
    "        '''\n",
    "\n",
    "        # bboxes = [[class,x,y,w,h,c],...]. c = confidence_score. filter predicted bboxes by confidence_threshold.\n",
    "        \n",
    "        pred = np.array([p for p in pred if p[-1] > self.confidence_threshold])\n",
    "        \n",
    "        \n",
    "        # 행 : pred, 열 : gt\n",
    "        if self.iou_table_per_img[imgidx] is not None :\n",
    "            iou_table = self.iou_table_per_img[imgidx]\n",
    "        else : \n",
    "            iou_table = torch.zeros((len(pred), len(gt)))\n",
    "            for j, pred_bbox in enumerate(pred) :\n",
    "                for i, gt_bbox in enumerate(gt) :\n",
    "                    iou_table[j][i] = IoU(pred_bbox[..., 1:], gt_bbox[..., 1:])\n",
    "            self.iou_table_per_img[imgidx] = iou_table\n",
    "        # if there are more than one prediction box matched with on gt box, then we choose the predicition with the highest IoU as TP, and treat other matches as FP.     \n",
    "        filtered_iou_table = torch.zeros_like(iou_table)\n",
    "        filtered_iou_table[torch.argmax(iou_table, axis = 0), torch.arange(iou_table.shape[1])] = torch.max(iou_table, axis = 0)[0] # this will leave only one highest IoU per gts\n",
    "        \n",
    "        result = filtered_iou_table > iou_threshold\n",
    "\n",
    "        TP = result.any(axis = 1).sum()\n",
    "        FP = len(pred) - TP\n",
    "        FN = len(gt) - result.any(axis = 0).sum()\n",
    "\n",
    "        return TP.item(), FP.item(), FN.item()\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    def calculate(self) :\n",
    "        ## TODO : add typing of variables\n",
    "        '''\n",
    "        preds : list of numpy array. []\n",
    "        gts \n",
    "        iou_threshold_range : (minimum_threshold, maximum_threshold, interval)\n",
    "        '''\n",
    "        for imgidx, (pred_by_img, gt_by_img) in enumerate(zip(self.preds, self.gts)) :\n",
    "            for cls_label in range(self.num_classes) :\n",
    "                cls_preds = pred_by_img[pred_by_img[..., 0] == cls_label]\n",
    "                cls_gts = gt_by_img[gt_by_img[..., 0] == cls_label]\n",
    "\n",
    "                # assert (cls_preds.shape == cls_gts.shape) and (cls_preds.ndim == cls_gts.ndim == 2 and cls_preds.shape[-1] == cls_gts.shape[-1] == 5), \\\n",
    "                #             'pred and gt shape = (# of bboxes over images, len([x,y,w,h,c]) )'\n",
    "\n",
    "                for iou_threshold in self.iou_threshold_range :\n",
    "                    TP, FP, FN = self.calculate_PR(imgidx, cls_preds, cls_gts, iou_threshold)\n",
    "                    self.TOTAL_TP[cls_label][iou_threshold] += TP\n",
    "                    self.TOTAL_FP[cls_label][iou_threshold] += FP\n",
    "                    self.TOTAL_FN[cls_label][iou_threshold] += FN\n",
    "\n",
    "        # calculate Precision and Recall\n",
    "\n",
    "        for cls_label in range(self.num_classes) :\n",
    "            for iou_threshold in self.iou_threshold_range :\n",
    "                precision = self.TOTAL_TP[cls_label][iou_threshold] / (self.TOTAL_TP[cls_label][iou_threshold] + self.TOTAL_FP[cls_label][iou_threshold])\n",
    "                recall = self.TOTAL_TP[cls_label][iou_threshold] / (self.TOTAL_TP[cls_label][iou_threshold] + self.TOTAL_FN[cls_label][iou_threshold])\n",
    "\n",
    "                self.total_statistics.append([cls_label, iou_threshold, precision, recall])\n",
    "\n",
    "        self.total_statistics = np.array(self.total_statistics)\n",
    "\n",
    "        # mean average precision = sum(avg_cls_precision) / num_classes. avg_cls_precision = sum of cls_precisions in different recalls / \n",
    "        for cls_label in range(self.num_classes) :\n",
    "\n",
    "        # interpolated precision\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "## read sample and test \n",
    "# 00001.txt gt\n",
    "gt1= ['person 0.22 0.22 0.19 0.28 1',\n",
    "'person 0.7475 0.77 0.20500000000000002 0.31 1']\n",
    "# 00001.txt pred\n",
    "pred1 = ['person .88 0.10250000000000001 0.455 0.155 0.24',\n",
    "'person .70 0.6950000000000001 0.7225 0.2 0.335',\n",
    "'person .80 0.7425 0.2125 0.245 0.335',]\n",
    "# 00002.txt gt\n",
    "gt2= ['person 0.7225 0.1925 0.215 0.275 1',\n",
    "'person 0.3375 0.7725 0.295 0.225 1',]\n",
    "# 00002.txt pred\n",
    "pred2 = ['person .71 0.48 0.7000000000000001 0.32 0.29',\n",
    "'person .54 0.28 0.8175 0.3 0.23500000000000001',\n",
    "'person .74 0.2025 0.1775 0.215 0.17500000000000002',]\n",
    "# 00003.txt gt\n",
    "gt3= ['person 0.1675 0.19 0.17500000000000002 0.24 1',\n",
    "'person 0.7375 0.26 0.245 0.22 1',\n",
    "'person 0.6125 0.8125 0.23500000000000001 0.23500000000000001 1',]\n",
    "# 00003.txt pred\n",
    "pred3 = ['person .18 0.7375 0.17250000000000001 0.385 0.195',\n",
    "'person .67 0.545 0.4275 0.23 0.225',\n",
    "'person .38 0.89 0.4425 0.18 0.265',\n",
    "'person .91 0.6425 0.7725 0.23500000000000001 0.23500000000000001',\n",
    "'person .44 0.19 0.85 0.2 0.22',]\n",
    "\n",
    "# 00004.txt gt\n",
    "gt4= ['person 0.365 0.34 0.2 0.26 1',\n",
    "'person 0.8475 0.3 0.155 0.17 1',]\n",
    "# 00004.txt pred\n",
    "pred4 = ['person .35 0.485 0.20500000000000002 0.14 0.13',\n",
    "'person .78 0.245 0.5075000000000001 0.21 0.335',\n",
    "'person .45 0.4975 0.5425 0.125 0.195',\n",
    "'person .14 0.2 0.84 0.3 0.13',]\n",
    "\n",
    "# 00005.txt gt\n",
    "gt5= ['person 0.405 0.28250000000000003 0.22 0.255 1',\n",
    "'person 0.325 0.77 0.17 0.26 1',]\n",
    "# 00005.txt pred\n",
    "pred5 = ['person .62 0.32 0.305 0.14 0.23',\n",
    "'person .44 0.6075 0.125 0.265 0.14',\n",
    "'person .95 0.325 0.7275 0.36 0.145',\n",
    "'person .23 0.325 0.8875000000000001 0.36 0.145',]\n",
    "\n",
    "# 00006.txt gt\n",
    "gt6= ['person 0.31 0.635 0.26 0.38 1',\n",
    "'person 0.42 0.4575 0.22 0.335 1',]\n",
    "# 00006.txt pred\n",
    "pred6 = ['person .45 0.4 0.335 0.37 0.19',\n",
    "'person .84 0.1575 0.8625 0.145 0.17500000000000002',\n",
    "'person .43 0.5375 0.655 0.125 0.21',]\n",
    "\n",
    "# 00007.txt gt\n",
    "gt7= ['person 0.2775 0.3125 0.275 0.315 1',\n",
    "'person 0.41500000000000004 0.48 0.25 0.29 1',]\n",
    "# 00007.txt pred\n",
    "pred7 = ['person .48 0.3325 0.32 0.505 0.44',\n",
    "'person .95 0.2575 0.7025 0.185 0.245',]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_dict = {'person' : 0}\n",
    "\n",
    "def convert_bbox(infos) : \n",
    "    bboxes = []\n",
    "    for info in infos :\n",
    "        classlabel, x, y, w, h, c = info.split(' ')\n",
    "        classlabel = class_dict[classlabel]\n",
    "        x,y,w,h,c =  map(float, [x,y,w,h, c])\n",
    "        bboxes.append([classlabel, x, y, w, h, c])\n",
    "    return bboxes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "gts = [torch.tensor(convert_bbox(g)) for g in [gt1,gt2,gt3,gt4,gt5,gt6,gt7]]\n",
    "preds = [torch.tensor(convert_bbox(p)) for p in [pred1,pred2,pred3,pred4,pred5,pred6,pred7]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[0.0000, 0.2200, 0.2200, 0.1900, 0.2800, 1.0000],\n",
       "         [0.0000, 0.7475, 0.7700, 0.2050, 0.3100, 1.0000]]),\n",
       " tensor([[0.0000, 0.7225, 0.1925, 0.2150, 0.2750, 1.0000],\n",
       "         [0.0000, 0.3375, 0.7725, 0.2950, 0.2250, 1.0000]]),\n",
       " tensor([[0.0000, 0.1675, 0.1900, 0.1750, 0.2400, 1.0000],\n",
       "         [0.0000, 0.7375, 0.2600, 0.2450, 0.2200, 1.0000],\n",
       "         [0.0000, 0.6125, 0.8125, 0.2350, 0.2350, 1.0000]]),\n",
       " tensor([[0.0000, 0.3650, 0.3400, 0.2000, 0.2600, 1.0000],\n",
       "         [0.0000, 0.8475, 0.3000, 0.1550, 0.1700, 1.0000]]),\n",
       " tensor([[0.0000, 0.4050, 0.2825, 0.2200, 0.2550, 1.0000],\n",
       "         [0.0000, 0.3250, 0.7700, 0.1700, 0.2600, 1.0000]]),\n",
       " tensor([[0.0000, 0.3100, 0.6350, 0.2600, 0.3800, 1.0000],\n",
       "         [0.0000, 0.4200, 0.4575, 0.2200, 0.3350, 1.0000]]),\n",
       " tensor([[0.0000, 0.2775, 0.3125, 0.2750, 0.3150, 1.0000],\n",
       "         [0.0000, 0.4150, 0.4800, 0.2500, 0.2900, 1.0000]])]"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAP_metrics = MeanAveragePrecisionMetrics(gts, preds, num_classes = 1, iou_threshold_range = (0.2, 0.1, 0.6), confidence_threshold = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_23192\\2250794420.py:54: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
      "  pred = np.array([p for p in pred if p[-1] > self.confidence_threshold])\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_23192\\2250794420.py:54: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  pred = np.array([p for p in pred if p[-1] > self.confidence_threshold])\n"
     ]
    }
   ],
   "source": [
    "MAP_metrics.calculate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.2       , 0.33333333, 0.46666667, 0.6       ])"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAP_metrics.iou_threshold_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_statistics = MAP_metrics.total_statistics\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0.], dtype=torch.float64)"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# statistics : class, iou_threshold, precision, recall\n",
    "# by class\n",
    "\n",
    "torch.trapz(torch.tensor(total_statistics[..., 2:3]) , torch.tensor(total_statistics[..., 2:4]), dim = -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.2       , 0.20833333, 0.33333333],\n",
       "       [0.        , 0.33333333, 0.125     , 0.2       ],\n",
       "       [0.        , 0.46666667, 0.125     , 0.2       ],\n",
       "       [0.        , 0.6       , 0.04166667, 0.06666667]])"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.1: 3}"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{0.1 : 3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.6, 0.7, 0.8])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samp[np.argmax(samp, axis = 0), range(samp.shape[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0. , 0. , 0.8],\n",
       "       [0.6, 0.7, 0. ]])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samp_zeros[np.argmax(samp, axis = 0), range(samp.shape[1])] = np.max(samp, axis = 0)\n",
    "\n",
    "samp_zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(samp, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5, 0.6, 0.8],\n",
       "       [0.6, 0.7, 0.3]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samp[..., [0,1,2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5000, 0.6000, 0.8000],\n",
       "        [0.6000, 0.7000, 0.3000],\n",
       "        [0.6000, 0.7000, 0.3000]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "samp = torch.tensor([[0.5, 0.6, 0.8],\n",
    "                     [0.6, 0.7, 0.3]])\n",
    "\n",
    "samp[[0,1,1], ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c6e4e9f98eb68ad3b7c296f83d20e6de614cb42e90992a65aa266555a3137d0d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
