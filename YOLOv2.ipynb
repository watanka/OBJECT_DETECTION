{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2 ways to improve the performance\n",
    "# yolov2 : changes in model configurations\n",
    "# yolo9000 : changes in model training method. joint training of classification and object detection.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from global_utils import IoU\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anchor Boxes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### k-mean clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## https://towardsdatascience.com/create-your-own-k-means-clustering-algorithm-in-python-d7d4c9077670\n",
    "\n",
    "def KmeanClustering(bboxes, max_iters, k = 5) :\n",
    "    '''\n",
    "    read out whole bounding boxes from train datasets, and perform k mean clusterings\n",
    "    bboxes = (x_center, y_center, w, h, c). Here ratios are respect to the image size, NOT grid cell.\n",
    "    max_iters : number of maximum iterations\n",
    "    k : number of clusters\n",
    "    '''\n",
    "\n",
    "    w = bboxes[:, 2]\n",
    "    h = bboxes[:, 3]\n",
    "\n",
    "    # initialize the centroid\n",
    "    min_w, max_w = min(w), max(w)\n",
    "    min_h, max_h = min(h), max(h)\n",
    "    # uniformly distribute the k cluster centroids\n",
    "    centroids = [((max_w - min_w) * (i+1), (max_h - min_h) * (i+1)) for i in range(k)]\n",
    "\n",
    "    prev_centroids = None\n",
    "    iteration = 0\n",
    "\n",
    "\n",
    "    while np.not_equal(centroids, prev_centroid).any() or iteration < max_iters :\n",
    "        \n",
    "        sorted_points = [[] for _ in range(k)]\n",
    "\n",
    "        for (_, _, w, h, _) in bboxes :\n",
    "            \n",
    "            # Suppose x_center and y_center are same for centroid and data point here, we just want the ratio of w, h.\n",
    "            x, y = 0.5, 0.5\n",
    "\n",
    "\n",
    "\n",
    "            dist = np.array([IoU(np.array([x,y,w,h]), np.array([x,y,centroid_w, centroid_h]) ) \\\n",
    "                                for (centroid_w, centroid_h) in centroids])\n",
    "\n",
    "            centroid_idx = np.argmax(dist)\n",
    "            sorted_points[centroid_idx].append([w, h])\n",
    "\n",
    "        prev_centroids = centroids\n",
    "        sorted_points = np.array(sorted_points)\n",
    "        centroids = [(np.mean(cluster[:,0]), np.mean(cluster[:,1]) ) for cluster in sorted_points]\n",
    "\n",
    "        # if any new centroids has NaN, then substitute back to previous centroids\n",
    "        centroids[np.isnan(centroids)] = prev_centroids[np.isnan(centroids)]\n",
    "\n",
    "        iteration += 1\n",
    "\n",
    "    return centroids\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "reference : https://github.com/rafaelpadilla/Object-Detection-Metrics\n",
    "usage : validation, evaluation. \n",
    "predictions and gts will be handed by reading gtfile directly, since dataloader limits the number of gt bounding box\n",
    "'''\n",
    "\n",
    "\n",
    "from global_utils import IoU\n",
    "\n",
    "## MAP\n",
    "\n",
    "class MeanAveragePrecisionMetrics :\n",
    "    def __init__(self, gts, preds, iou_threshold_range, confidence_threshold) :\n",
    "        '''\n",
    "        gts, preds = [[[class, x, y, w, h, c],...], ...] # imgs x bboxes\n",
    "\n",
    "        classes : should be collected from gt.\n",
    "        iou_threshold_range : (min_threshold, interval, max_threshold). e.g) IoU(0.6, 0.1, 0.9) = [0.6, 0.7, 0.8, 0.9]\n",
    "        confidence_threshold : predicted bounding boxes are filtered by confidence threshold\n",
    "        '''\n",
    "        self.gts = gts\n",
    "        self.preds = preds\n",
    "        assert len(gts) == len(preds), '# of images should be the same for predictions and ground truths.'\n",
    "        \n",
    "        cnt_cls = set()\n",
    "        for gts_per_img in self.gts :\n",
    "            for gt_bbox in gts_per_img :\n",
    "                cnt_cls.add(int(gt_bbox[0]))\n",
    "        self.classes = list(cnt_cls)\n",
    "\n",
    "        # convert iou_threshold_range into list\n",
    "        min_threshold, interval, max_threshold  = iou_threshold_range\n",
    "        self.iou_threshold_range = np.linspace(min_threshold, max_threshold, num= int((max_threshold - min_threshold)//interval + 1))\n",
    "        \n",
    "        self.confidence_threshold = confidence_threshold\n",
    "        self.iou_table_per_img = {imgidx : None for imgidx in range(len(gts))}\n",
    "\n",
    "        # self.total_iou_table = {clslabel : {iou_threshold : None \\\n",
    "        #                                         for iou_threshold in self.iou_threshold_range} \\\n",
    "        #                                             for clslabel in range(num_classes)}\n",
    "\n",
    "        self.TOTAL_TP = [{iou_threshold : 0 for iou_threshold in self.iou_threshold_range} for _ in range(len(self.classes))]\n",
    "        self.TOTAL_FP = [{iou_threshold : 0 for iou_threshold in self.iou_threshold_range} for _ in range(len(self.classes))]\n",
    "        self.TOTAL_FN = [{iou_threshold : 0 for iou_threshold in self.iou_threshold_range} for _ in range(len(self.classes))]\n",
    "\n",
    "        self.total_statistics = []\n",
    "\n",
    "\n",
    "    def calculate_PR(self, imgidx, pred, gt, iou_threshold) :\n",
    "        '''\n",
    "        calculate precision and recall per classes\n",
    "        Recall = TP / (TP+FN)\n",
    "        Precision = TP / (TP + FP)\n",
    "        1. match preds and gts using IoU\n",
    "        2. matched preds will be TP, and remaining unmatched preds will be FP, and unmatched gt are FN.\n",
    "        '''\n",
    "\n",
    "        # bboxes = [[class,x,y,w,h,c],...]. c = confidence_score. filter predicted bboxes by confidence_threshold.\n",
    "        \n",
    "        pred = np.array([p for p in pred if p[-1] > self.confidence_threshold])\n",
    "        \n",
    "        \n",
    "        # 행 : pred, 열 : gt\n",
    "        if self.iou_table_per_img[imgidx] is not None :\n",
    "            iou_table = self.iou_table_per_img[imgidx]\n",
    "        else : \n",
    "            iou_table = torch.zeros((len(pred), len(gt)))\n",
    "            for j, pred_bbox in enumerate(pred) :\n",
    "                for i, gt_bbox in enumerate(gt) :\n",
    "                    iou_table[j][i] = IoU(pred_bbox[..., 1:], gt_bbox[..., 1:])\n",
    "            self.iou_table_per_img[imgidx] = iou_table\n",
    "        # if there are more than one prediction box matched with on gt box, then we choose the predicition with the highest IoU as TP, and treat other matches as FP.     \n",
    "        filtered_iou_table = torch.zeros_like(iou_table)\n",
    "        filtered_iou_table[torch.argmax(iou_table, axis = 0), torch.arange(iou_table.shape[1])] = torch.max(iou_table, axis = 0)[0] # this will leave only one highest IoU per gts\n",
    "        \n",
    "        result = filtered_iou_table > iou_threshold\n",
    "\n",
    "        TP = result.any(axis = 1).sum()\n",
    "        FP = len(pred) - TP\n",
    "        FN = len(gt) - result.any(axis = 0).sum()\n",
    "\n",
    "        return TP.item(), FP.item(), FN.item()\n",
    "\n",
    "    def calculate_average_precision(self, precision, recall) :\n",
    "\n",
    "        precision = list(precision)[:] # [:] = copy list\n",
    "        recall = list(recall)[:]\n",
    "\n",
    "        mean_precision = [0] + precision + [0] \n",
    "        mean_recall = [0] + recall + [0]\n",
    "        \"\"\"\n",
    "        This part makes the precision monotonically decreasing\n",
    "            (goes from the end to the beginning)\n",
    "        \"\"\"\n",
    "        for i in range(len(mean_precision)-2, -1, -1) :\n",
    "            mean_precision[i] = max(mean_precision[i], mean_precision[i+1])\n",
    "        \n",
    "        \"\"\"\n",
    "        This part creates a list of indexes where the recall changes\n",
    "        \"\"\"\n",
    "        i_list = []\n",
    "        for i in range(1, len(mean_recall)) :\n",
    "            if mean_recall[i] != mean_recall[i-1] :\n",
    "                i_list.append(i)\n",
    "        \"\"\"\n",
    "        The Average Precision (AP) is the area under the curve\n",
    "            (numerical integration)\n",
    "        \"\"\"\n",
    "        average_precision = 0.0\n",
    "        for i in i_list :\n",
    "            average_precision += ((mean_recall[i] - mean_recall[i-1]) * mean_precision[i])\n",
    "\n",
    "        # average_precision = torch.mean(torch.trapz(torch.tensor(precision), torch.tensor(recall))).item()\n",
    "        return average_precision\n",
    "\n",
    "\n",
    "    def calculate(self) :\n",
    "        ## TODO : add typing of variables\n",
    "        '''\n",
    "        preds : list of numpy array. []\n",
    "        gts \n",
    "        iou_threshold_range : (minimum_threshold, maximum_threshold, interval)\n",
    "        '''\n",
    "        for imgidx, (pred_by_img, gt_by_img) in enumerate(zip(self.preds, self.gts)) :\n",
    "            for cls_label in self.classes :\n",
    "                cls_preds = pred_by_img[pred_by_img[..., 0] == cls_label]\n",
    "                cls_gts = gt_by_img[gt_by_img[..., 0] == cls_label]\n",
    "\n",
    "                # assert (cls_preds.shape == cls_gts.shape) and (cls_preds.ndim == cls_gts.ndim == 2 and cls_preds.shape[-1] == cls_gts.shape[-1] == 5), \\\n",
    "                #             'pred and gt shape = (# of bboxes over images, len([x,y,w,h,c]) )'\n",
    "\n",
    "                for iou_threshold in self.iou_threshold_range :\n",
    "                    TP, FP, FN = self.calculate_PR(imgidx, cls_preds, cls_gts, iou_threshold)\n",
    "                    self.TOTAL_TP[cls_label][iou_threshold] += TP\n",
    "                    self.TOTAL_FP[cls_label][iou_threshold] += FP\n",
    "                    self.TOTAL_FN[cls_label][iou_threshold] += FN\n",
    "\n",
    "        # calculate Precision and Recall\n",
    "\n",
    "        for cls_label in self.classes :\n",
    "            for iou_threshold in self.iou_threshold_range :\n",
    "                ## round by 3 decimal points\n",
    "                precision = round(self.TOTAL_TP[cls_label][iou_threshold] / (self.TOTAL_TP[cls_label][iou_threshold] + self.TOTAL_FP[cls_label][iou_threshold] + 1e-6), 3) # add 1e-6 to prevent divisionbyzero\n",
    "                recall = round(self.TOTAL_TP[cls_label][iou_threshold] / (self.TOTAL_TP[cls_label][iou_threshold] + self.TOTAL_FN[cls_label][iou_threshold] + 1e-6), 3)\n",
    "\n",
    "                self.total_statistics.append([cls_label, iou_threshold, precision, recall])\n",
    "\n",
    "        self.total_statistics = np.array(self.total_statistics)\n",
    "\n",
    "        # mean average precision = sum(avg_cls_precision) / num_classes. avg_cls_precision = sum of cls_precisions in different recalls / \n",
    "        mean_average_precision = 0\n",
    "        \n",
    "        for cls_label in self.classes :\n",
    "            class_statistics = self.total_statistics[self.total_statistics[..., 0] == cls_label][...,2:4].tolist() # ious x [precision, recall]\n",
    "            class_statistics = sorted(class_statistics, key = lambda x : x[1])\n",
    "            precision, recall = zip(*class_statistics)\n",
    "            \n",
    "            average_precision = self.calculate_average_precision(precision, recall)\n",
    "            mean_average_precision += average_precision\n",
    "            \n",
    "\n",
    "        mean_average_precision /= len(self.classes)\n",
    "\n",
    "        return mean_average_precision\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "## read sample and test \n",
    "# 00001.txt gt\n",
    "gt1= ['person 0.22 0.22 0.19 0.28 1',\n",
    "'person 0.7475 0.77 0.20500000000000002 0.31 1']\n",
    "# 00001.txt pred\n",
    "pred1 = ['person .88 0.10250000000000001 0.455 0.155 0.24',\n",
    "'person .70 0.6950000000000001 0.7225 0.2 0.335',\n",
    "'person .80 0.7425 0.2125 0.245 0.335',]\n",
    "# 00002.txt gt\n",
    "gt2= ['person 0.7225 0.1925 0.215 0.275 1',\n",
    "'person 0.3375 0.7725 0.295 0.225 1',]\n",
    "# 00002.txt pred\n",
    "pred2 = ['person .71 0.48 0.7000000000000001 0.32 0.29',\n",
    "'person .54 0.28 0.8175 0.3 0.23500000000000001',\n",
    "'person .74 0.2025 0.1775 0.215 0.17500000000000002',]\n",
    "# 00003.txt gt\n",
    "gt3= ['person 0.1675 0.19 0.17500000000000002 0.24 1',\n",
    "'person 0.7375 0.26 0.245 0.22 1',\n",
    "'person 0.6125 0.8125 0.23500000000000001 0.23500000000000001 1',]\n",
    "# 00003.txt pred\n",
    "pred3 = ['person .18 0.7375 0.17250000000000001 0.385 0.195',\n",
    "'person .67 0.545 0.4275 0.23 0.225',\n",
    "'person .38 0.89 0.4425 0.18 0.265',\n",
    "'person .91 0.6425 0.7725 0.23500000000000001 0.23500000000000001',\n",
    "'person .44 0.19 0.85 0.2 0.22',]\n",
    "\n",
    "# 00004.txt gt\n",
    "gt4= ['person 0.365 0.34 0.2 0.26 1',\n",
    "'person 0.8475 0.3 0.155 0.17 1',]\n",
    "# 00004.txt pred\n",
    "pred4 = ['person .35 0.485 0.20500000000000002 0.14 0.13',\n",
    "'person .78 0.245 0.5075000000000001 0.21 0.335',\n",
    "'person .45 0.4975 0.5425 0.125 0.195',\n",
    "'person .14 0.2 0.84 0.3 0.13',]\n",
    "\n",
    "# 00005.txt gt\n",
    "gt5= ['person 0.405 0.28250000000000003 0.22 0.255 1',\n",
    "'person 0.325 0.77 0.17 0.26 1',]\n",
    "# 00005.txt pred\n",
    "pred5 = ['person .62 0.32 0.305 0.14 0.23',\n",
    "'person .44 0.6075 0.125 0.265 0.14',\n",
    "'person .95 0.325 0.7275 0.36 0.145',\n",
    "'person .23 0.325 0.8875000000000001 0.36 0.145',]\n",
    "\n",
    "# 00006.txt gt\n",
    "gt6= ['person 0.31 0.635 0.26 0.38 1',\n",
    "'person 0.42 0.4575 0.22 0.335 1',]\n",
    "# 00006.txt pred\n",
    "pred6 = ['person .45 0.4 0.335 0.37 0.19',\n",
    "'person .84 0.1575 0.8625 0.145 0.17500000000000002',\n",
    "'person .43 0.5375 0.655 0.125 0.21',]\n",
    "\n",
    "# 00007.txt gt\n",
    "gt7= ['person 0.2775 0.3125 0.275 0.315 1',\n",
    "'person 0.41500000000000004 0.48 0.25 0.29 1',]\n",
    "# 00007.txt pred\n",
    "pred7 = ['person .48 0.3325 0.32 0.505 0.44',\n",
    "'person .95 0.2575 0.7025 0.185 0.245',]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_dict = {'person' : 0}\n",
    "\n",
    "def convert_bbox(infos) : \n",
    "    bboxes = []\n",
    "    for info in infos :\n",
    "        classlabel, x, y, w, h, c = info.split(' ')\n",
    "        classlabel = class_dict[classlabel]\n",
    "        x,y,w,h,c =  map(float, [x,y,w,h, c])\n",
    "        bboxes.append([classlabel, x, y, w, h, c])\n",
    "    return np.array(bboxes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "gts = [torch.tensor(convert_bbox(g)) for g in [gt1,gt2,gt3,gt4,gt5,gt6,gt7]]\n",
    "preds = [torch.tensor(convert_bbox(p)) for p in [pred1,pred2,pred3,pred4,pred5,pred6,pred7]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAP_metrics = MeanAveragePrecisionMetrics(gts, preds,  iou_threshold_range = (0.2, 0.1, 0.6), confidence_threshold = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_6480\\784397417.py:60: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
      "  pred = np.array([p for p in pred if p[-1] > self.confidence_threshold])\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_6480\\784397417.py:60: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  pred = np.array([p for p in pred if p[-1] > self.confidence_threshold])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.06926399999999999"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAP_metrics.calculate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.2       , 0.33333333, 0.46666667, 0.6       ])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAP_metrics.iou_threshold_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.2       , 0.208     , 0.333     ],\n",
       "       [0.        , 0.33333333, 0.125     , 0.2       ],\n",
       "       [0.        , 0.46666667, 0.125     , 0.2       ],\n",
       "       [0.        , 0.6       , 0.042     , 0.067     ]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAP_metrics.total_statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.015701000000000003"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(0.042 * 0.067 + 0.125 * 0.133 + 0.208 * 0.133)/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c6e4e9f98eb68ad3b7c296f83d20e6de614cb42e90992a65aa266555a3137d0d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
